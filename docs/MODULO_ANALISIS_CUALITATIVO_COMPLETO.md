# ğŸ“Š MÃ³dulo de AnÃ¡lisis Cualitativo Avanzado - DocumentaciÃ³n Completa

## ğŸ“‹ Tabla de Contenidos

1. [IntroducciÃ³n](#introducciÃ³n)
2. [Arquitectura del MÃ³dulo](#arquitectura-del-mÃ³dulo)
3. [Funcionalidades Principales](#funcionalidades-principales)
4. [GuÃ­a de Uso](#guÃ­a-de-uso)
5. [API Reference](#api-reference)
6. [Mejoras Implementadas](#mejoras-implementadas)
7. [Ejemplos de Uso](#ejemplos-de-uso)
8. [Troubleshooting](#troubleshooting)
9. [Roadmap](#roadmap)

---

## ğŸ¯ IntroducciÃ³n

El **MÃ³dulo de AnÃ¡lisis Cualitativo Avanzado** es un sistema integral de procesamiento y anÃ¡lisis de contenido textual que utiliza tÃ©cnicas avanzadas de Procesamiento de Lenguaje Natural (NLP) y visualizaciones interactivas. Este mÃ³dulo ha sido completamente refactorizado y mejorado para ofrecer:

- âœ… **AnÃ¡lisis inteligente** con extracciÃ³n de conceptos usando n-gramas
- âœ… **Visualizaciones interactivas** (mapas conceptuales y mentales)
- âœ… **Arquitectura modular** con clases especializadas
- âœ… **AnÃ¡lisis de sentimientos** avanzado
- âœ… **TriangulaciÃ³n** para una o mÃºltiples fuentes
- âœ… **Sistema de cache** optimizado
- âœ… **Procesamiento paralelo**

### ğŸ¯ Objetivos del MÃ³dulo

1. **ExtracciÃ³n Inteligente**: Identificar conceptos clave usando tÃ©cnicas avanzadas de NLP
2. **AnÃ¡lisis Estructural**: Comprender la organizaciÃ³n y jerarquÃ­a del contenido
3. **VisualizaciÃ³n**: Crear representaciones grÃ¡ficas interactivas del conocimiento
4. **ValidaciÃ³n**: TriangulaciÃ³n de informaciÃ³n para mayor confiabilidad
5. **OptimizaciÃ³n**: Rendimiento mejorado con cache y procesamiento paralelo

---

## ğŸ—ï¸ Arquitectura del MÃ³dulo

### ğŸ“ Estructura General

```
modules/qualitative_analysis.py
â”œâ”€â”€ 1. IMPORTS Y CONFIGURACIÃ“N GLOBAL
â”œâ”€â”€ 2. ENUMS, DATACLASSES Y ESTRUCTURAS DE DATOS
â”œâ”€â”€ 3. CLASES BASE Y INTERFACES
â”œâ”€â”€ 4. GESTIÃ“N DE CACHE Y MEMORIA
â”œâ”€â”€ 5. PREPROCESAMIENTO DE TEXTO
â”œâ”€â”€ 6. EXTRACCIÃ“N DE CONCEPTOS
â”œâ”€â”€ 7. ANÃLISIS DE TEMAS
â”œâ”€â”€ 8. ANÃLISIS DE SENTIMIENTOS
â”œâ”€â”€ 9. CLUSTERING Y AGRUPACIÃ“N
â”œâ”€â”€ 10. MAPAS CONCEPTUALES INTERACTIVOS
â”œâ”€â”€ 11. MAPAS MENTALES
â”œâ”€â”€ 12. RESUMENES AUTOMÃTICOS
â”œâ”€â”€ 13. ANÃLISIS DE TRIANGULACIÃ“N
â”œâ”€â”€ 14. NUBES DE PALABRAS
â”œâ”€â”€ 15. VISUALIZACIONES Y GRÃFICOS
â”œâ”€â”€ 16. ANÃLISIS PARALELO Y OPTIMIZACIÃ“N
â”œâ”€â”€ 17. MÃ‰TODOS DE CONFIGURACIÃ“N
â”œâ”€â”€ 18. FUNCIONES DE RENDERIZADO (STREAMLIT)
â””â”€â”€ 19. FUNCIÃ“N PRINCIPAL DE RENDERIZADO
```

### ğŸ”§ Componentes Principales

#### **1. Clases Especializadas**

```python
class TextPreprocessor:
    """Preprocesador de texto especializado"""
    - get_spanish_stopwords()
    - preprocess_text()

class ConceptExtractor:
    """Extractor de conceptos especializado"""
    - analyze()
    - _extract_concepts_advanced()
    - _extract_with_tfidf()
    - _extract_with_frequency()

class ThemeAnalyzer:
    """Analizador de temas especializado"""
    - analyze()
    - _extract_themes_advanced()
    - _extract_themes_with_lda()
    - _extract_themes_with_clustering()

class SentimentAnalyzer:
    """Analizador de sentimientos especializado"""
    - analyze()
    - _analyze_sentiments_advanced()
    - _analyze_with_textblob_vader()

class CacheManager:
    """Gestor de cache optimizado"""
    - get(), set(), clear()
    - _evict_oldest()
    - get_stats()
```

#### **2. Clase Principal**

```python
class AdvancedQualitativeAnalyzer:
    """Analizador cualitativo avanzado con arquitectura modular mejorada"""
    
    # MÃ©todos principales de anÃ¡lisis
    - extract_key_concepts()
    - extract_advanced_themes()
    - advanced_sentiment_analysis()
    - perform_clustering()
    - perform_triangulation_analysis()
    
    # Visualizaciones
    - create_interactive_concept_map()
    - create_interactive_mind_map()
    - generate_word_cloud()
    
    # MÃ©todos avanzados
    - _extract_concepts_with_ngrams()
    - _identify_intelligent_main_theme()
    - _analyze_concept_hierarchy_with_ai()
    - perform_parallel_analysis()
```

---

## ğŸš€ Funcionalidades Principales

### 1. ğŸ“Š **ExtracciÃ³n de Conceptos**

#### **MÃ©todo Tradicional**
```python
concepts = analyzer.extract_key_concepts(chunks, min_freq=2)
```

#### **MÃ©todo Avanzado con N-gramas**
```python
concepts = analyzer._extract_concepts_with_ngrams(chunks, max_concepts=30)
```

**CaracterÃ­sticas:**
- âœ… Detecta frases de 1-3 palabras
- âœ… Prioriza conceptos compuestos
- âœ… Bonus de score para n-gramas
- âœ… Contexto enriquecido

### 2. ğŸ¯ **AnÃ¡lisis de Temas**

#### **LDA (Latent Dirichlet Allocation)**
```python
themes = analyzer.extract_advanced_themes(chunks, n_topics=10)
```

#### **Clustering JerÃ¡rquico**
```python
clusters = analyzer.perform_clustering(chunks, n_clusters=5)
```

### 3. ğŸ˜Š **AnÃ¡lisis de Sentimientos**

#### **TextBlob + VADER**
```python
sentiment = analyzer.advanced_sentiment_analysis(chunks)
```

**MÃ©tricas:**
- Polaridad (positivo/negativo)
- Subjetividad
- Tendencias temporales
- DistribuciÃ³n por fuente

### 4. ğŸ—ºï¸ **Mapas Conceptuales**

#### **GeneraciÃ³n Normal (RÃ¡pida)**
```python
html_file = analyzer.create_interactive_concept_map(chunks, layout_type="spring")
```

#### **GeneraciÃ³n con IA**
```python
# Usa anÃ¡lisis semÃ¡ntico profundo con LLM
structure = analyzer._analyze_concept_hierarchy_with_ai(chunks)
```

**CaracterÃ­sticas:**
- âœ… ExtracciÃ³n con n-gramas
- âœ… Tema central inteligente
- âœ… JerarquÃ­a de conceptos
- âœ… Relaciones cruzadas
- âœ… VisualizaciÃ³n interactiva con PyVis

### 5. ğŸ§  **Mapas Mentales**

#### **GeneraciÃ³n Mejorada**
```python
mind_map = analyzer.create_interactive_mind_map(chunks, node_spacing=350)
```

**Mejoras Visuales:**
- âœ… Texto blanco/gris claro para legibilidad
- âœ… Contenedor 1400x700px (pantalla completa)
- âœ… Espaciado mejorado (450px por defecto)
- âœ… FÃ­sica mÃ¡s suave para evitar nodos pegados
- âœ… TamaÃ±os de nodos aumentados

### 6. ğŸ”º **TriangulaciÃ³n**

#### **Multi-Fuente (ClÃ¡sica)**
```python
triangulation = analyzer.perform_triangulation_analysis(chunks)
```

#### **Fuente Ãšnica (Interna)**
```python
# AutomÃ¡tico cuando hay una sola fuente
triangulation = analyzer._perform_single_source_triangulation(chunks, source_name)
```

**Tipos de ValidaciÃ³n:**
- âœ… Multi-fuente: Conceptos en mÃºltiples documentos
- âœ… Interna: Conceptos en mÃºltiples secciones del mismo documento
- âœ… Confiabilidad calculada por frecuencia de apariciÃ³n

---

## ğŸ“– GuÃ­a de Uso

### ğŸ”§ **InicializaciÃ³n**

```python
from modules.qualitative_analysis import AdvancedQualitativeAnalyzer

# Crear instancia del analizador
analyzer = AdvancedQualitativeAnalyzer()

# Opcional: ConfiguraciÃ³n personalizada
from modules.qualitative_analysis import AnalysisConfig

config = AnalysisConfig(
    min_frequency=3,
    max_concepts=50,
    similarity_threshold=0.7,
    enable_cache=True,
    parallel_processing=True
)

analyzer = AdvancedQualitativeAnalyzer(config)
```

### ğŸ“Š **AnÃ¡lisis BÃ¡sico**

```python
# Cargar datos (chunks de documentos)
chunks = [
    {
        'content': 'Texto del documento...',
        'metadata': {'source_file': 'documento.pdf'}
    }
]

# Extraer conceptos clave
concepts = analyzer.extract_key_concepts(chunks)
print(f"Conceptos encontrados: {len(concepts)}")

# AnÃ¡lisis de temas
themes = analyzer.extract_advanced_themes(chunks, n_topics=8)
print(f"Temas identificados: {len(themes.get('topics', []))}")

# AnÃ¡lisis de sentimientos
sentiment = analyzer.advanced_sentiment_analysis(chunks)
print(f"Sentimiento promedio: {sentiment.get('overall_sentiment', {}).get('polarity', 0)}")
```

### ğŸ—ºï¸ **Visualizaciones**

```python
# Mapa conceptual
html_file = analyzer.create_interactive_concept_map(
    chunks, 
    layout_type="spring"  # "spring", "hierarchical", "circular"
)

# Mapa mental
mind_map_data = analyzer.create_interactive_mind_map(
    chunks,
    node_spacing=350,
    return_data=True
)

# Nube de palabras
wordcloud_file = analyzer.generate_word_cloud(chunks)
```

### ğŸ”º **TriangulaciÃ³n**

```python
# TriangulaciÃ³n automÃ¡tica (detecta si es 1 o mÃºltiples fuentes)
triangulation = analyzer.perform_triangulation_analysis(chunks)

if triangulation['analysis_mode'] == 'multi-source':
    print("AnÃ¡lisis multi-fuente")
elif triangulation['analysis_mode'] == 'single-source-internal':
    print("AnÃ¡lisis de triangulaciÃ³n interna")

# Mostrar conceptos validados
for concept in triangulation['triangulated_concepts'][:10]:
    print(f"{concept['concept']} - Confiabilidad: {concept['reliability']:.2%}")
```

### âš¡ **AnÃ¡lisis Paralelo**

```python
from modules.qualitative_analysis import AnalysisType

# Ejecutar mÃºltiples anÃ¡lisis en paralelo
analysis_types = [
    AnalysisType.CONCEPT_EXTRACTION,
    AnalysisType.THEME_ANALYSIS,
    AnalysisType.SENTIMENT_ANALYSIS,
    AnalysisType.CLUSTERING
]

results = analyzer.perform_parallel_analysis(chunks, analysis_types)

# Acceder a resultados especÃ­ficos
concepts_result = results['concept_extraction']
themes_result = results['theme_analysis']
```

---

## ğŸ”Œ API Reference

### **Clase Principal: AdvancedQualitativeAnalyzer**

#### **Constructor**
```python
def __init__(self, config: Optional[AnalysisConfig] = None)
```

#### **MÃ©todos de AnÃ¡lisis**

##### `extract_key_concepts(chunks, min_freq=2)`
Extrae conceptos clave de los chunks de texto.

**ParÃ¡metros:**
- `chunks` (List[Dict]): Lista de chunks de texto
- `min_freq` (int): Frecuencia mÃ­nima para considerar un concepto

**Retorna:**
- `List[Dict]`: Lista de conceptos con score y contexto

##### `extract_advanced_themes(chunks, n_topics=10)`
AnÃ¡lisis avanzado de temas usando LDA y clustering.

**ParÃ¡metros:**
- `chunks` (List[Dict]): Lista de chunks de texto
- `n_topics` (int): NÃºmero de temas a identificar

**Retorna:**
- `Dict`: Diccionario con temas, palabras clave y mÃ©tricas

##### `advanced_sentiment_analysis(chunks)`
AnÃ¡lisis de sentimientos usando TextBlob y VADER.

**ParÃ¡metros:**
- `chunks` (List[Dict]): Lista de chunks de texto

**Retorna:**
- `Dict`: AnÃ¡lisis de sentimientos con polaridad, subjetividad y tendencias

##### `perform_clustering(chunks, n_clusters=5)`
AgrupaciÃ³n de documentos usando K-means y DBSCAN.

**ParÃ¡metros:**
- `chunks` (List[Dict]): Lista de chunks de texto
- `n_clusters` (int): NÃºmero de clusters

**Retorna:**
- `Dict`: Resultados del clustering con clusters y mÃ©tricas

#### **MÃ©todos de VisualizaciÃ³n**

##### `create_interactive_concept_map(chunks, layout_type="spring")`
Crea un mapa conceptual interactivo.

**ParÃ¡metros:**
- `chunks` (List[Dict]): Lista de chunks de texto
- `layout_type` (str): Tipo de layout ("spring", "hierarchical", "circular")

**Retorna:**
- `str`: Ruta al archivo HTML generado

##### `create_interactive_mind_map(chunks, node_spacing=250, return_data=False)`
Crea un mapa mental interactivo.

**ParÃ¡metros:**
- `chunks` (List[Dict]): Lista de chunks de texto
- `node_spacing` (int): Espaciado entre nodos
- `return_data` (bool): Si retornar datos ademÃ¡s del HTML

**Retorna:**
- `Optional[Dict]`: Datos del mapa mental o None

##### `generate_word_cloud(chunks, source_filter=None)`
Genera una nube de palabras.

**ParÃ¡metros:**
- `chunks` (List[Dict]): Lista de chunks de texto
- `source_filter` (Optional[str]): Filtrar por fuente especÃ­fica

**Retorna:**
- `Optional[str]`: Ruta al archivo de imagen o None

#### **MÃ©todos Avanzados**

##### `_extract_concepts_with_ngrams(chunks, max_concepts=30)`
ExtracciÃ³n inteligente de conceptos usando n-gramas.

**ParÃ¡metros:**
- `chunks` (List[Dict]): Lista de chunks de texto
- `max_concepts` (int): NÃºmero mÃ¡ximo de conceptos

**Retorna:**
- `List[Dict]`: Lista de conceptos con n-gramas

##### `_identify_intelligent_main_theme(chunks, concepts)`
Identifica el tema central de forma inteligente.

**ParÃ¡metros:**
- `chunks` (List[Dict]): Lista de chunks de texto
- `concepts` (List[Dict]): Lista de conceptos extraÃ­dos

**Retorna:**
- `Dict`: Tema central con nombre y descripciÃ³n

##### `perform_triangulation_analysis(chunks)`
Realiza anÃ¡lisis de triangulaciÃ³n (1 o mÃºltiples fuentes).

**ParÃ¡metros:**
- `chunks` (List[Dict]): Lista de chunks de texto

**Retorna:**
- `Dict`: Resultados de triangulaciÃ³n con conceptos validados

---

## âœ¨ Mejoras Implementadas

### ğŸ¯ **Mejoras en Mapas Conceptuales**

#### **1. ExtracciÃ³n Inteligente con N-gramas**
```python
# ANTES: Palabras sueltas
concepts = ["inteligencia", "artificial", "machine", "learning"]

# AHORA: Frases completas
concepts = ["inteligencia artificial", "machine learning", "procesamiento natural"]
```

#### **2. Modo Normal por Defecto**
- âœ… GeneraciÃ³n 3-5x mÃ¡s rÃ¡pida
- âœ… Resultados mÃ¡s coherentes
- âœ… Modo IA como opciÃ³n avanzada

#### **3. Mejor SeparaciÃ³n Visual**
- âœ… Distancia entre nodos aumentada
- âœ… TamaÃ±os de nodos optimizados
- âœ… Colores mÃ¡s contrastantes

### ğŸ§  **Mejoras en Mapas Mentales**

#### **1. Legibilidad Mejorada**
```python
# Texto optimizado para fondo oscuro
'fontColor': '#ffffff'  # Blanco para nodos
'fontColor': '#e0e0e0'  # Gris claro para etiquetas
```

#### **2. Contenedor de Pantalla Completa**
```python
# TamaÃ±o optimizado
width=1400,   # +17% mÃ¡s ancho
height=700,   # +40% mÃ¡s alto
```

#### **3. Espaciado Mejorado**
```python
# ConfiguraciÃ³n por defecto mejorada
min_value=200,    # +33% mÃ¡s espaciado mÃ­nimo
value=450,        # +29% mÃ¡s espaciado por defecto
max_value=800,    # +33% mÃ¡s espaciado mÃ¡ximo
```

### ğŸ”º **Mejoras en TriangulaciÃ³n**

#### **1. Soporte para Fuente Ãšnica**
```python
def _perform_single_source_triangulation(self, chunks, source_name):
    """TriangulaciÃ³n interna dividiendo el documento en secciones"""
    # Divide en secciones de 3-5 chunks
    # Analiza conceptos por secciÃ³n
    # Identifica conceptos que aparecen en mÃºltiples secciones
```

#### **2. ValidaciÃ³n Mejorada**
- âœ… Confiabilidad por frecuencia de apariciÃ³n
- âœ… AnÃ¡lisis de distribuciÃ³n por secciones
- âœ… MÃ©tricas de validaciÃ³n cruzada

### ğŸ—ï¸ **Mejoras en Arquitectura**

#### **1. Clases Especializadas**
```python
# SeparaciÃ³n de responsabilidades
TextPreprocessor    # Preprocesamiento
ConceptExtractor    # ExtracciÃ³n de conceptos
ThemeAnalyzer       # AnÃ¡lisis de temas
SentimentAnalyzer   # AnÃ¡lisis de sentimientos
CacheManager        # GestiÃ³n de cache
```

#### **2. Sistema de Cache Optimizado**
```python
class CacheManager:
    def __init__(self, max_size=1000):
        self.cache = {}
        self.access_times = {}
        self.max_size = max_size
```

#### **3. Procesamiento Paralelo**
```python
def perform_parallel_analysis(self, chunks, analysis_types):
    """Ejecuta mÃºltiples anÃ¡lisis en paralelo usando ThreadPoolExecutor"""
    with ThreadPoolExecutor(max_workers=self.config.max_workers) as executor:
        # Procesamiento concurrente
```

---

## ğŸ’¡ Ejemplos de Uso

### ğŸ“Š **Ejemplo 1: AnÃ¡lisis Completo de Documento**

```python
from modules.qualitative_analysis import AdvancedQualitativeAnalyzer

# Inicializar analizador
analyzer = AdvancedQualitativeAnalyzer()

# Datos de ejemplo
chunks = [
    {
        'content': 'La inteligencia artificial estÃ¡ transformando la educaciÃ³n...',
        'metadata': {'source_file': 'educacion_ia.pdf'}
    },
    {
        'content': 'Machine learning permite personalizar el aprendizaje...',
        'metadata': {'source_file': 'educacion_ia.pdf'}
    }
]

# AnÃ¡lisis completo
print("ğŸ” Extrayendo conceptos...")
concepts = analyzer.extract_key_concepts(chunks)
print(f"âœ… {len(concepts)} conceptos encontrados")

print("ğŸ¯ Analizando temas...")
themes = analyzer.extract_advanced_themes(chunks, n_topics=5)
print(f"âœ… {len(themes['topics'])} temas identificados")

print("ğŸ˜Š Analizando sentimientos...")
sentiment = analyzer.advanced_sentiment_analysis(chunks)
print(f"âœ… Sentimiento: {sentiment['overall_sentiment']['label']}")

print("ğŸ”º Realizando triangulaciÃ³n...")
triangulation = analyzer.perform_triangulation_analysis(chunks)
print(f"âœ… {triangulation['validated_concepts']} conceptos validados")

print("ğŸ—ºï¸ Generando visualizaciones...")
concept_map = analyzer.create_interactive_concept_map(chunks)
mind_map = analyzer.create_interactive_mind_map(chunks)
wordcloud = analyzer.generate_word_cloud(chunks)

print("ğŸ‰ AnÃ¡lisis completo finalizado!")
```

### ğŸ—ºï¸ **Ejemplo 2: GeneraciÃ³n de Mapas Interactivos**

```python
# Mapa conceptual con diferentes layouts
layouts = ["spring", "hierarchical", "circular"]

for layout in layouts:
    print(f"Generando mapa conceptual con layout: {layout}")
    html_file = analyzer.create_interactive_concept_map(chunks, layout_type=layout)
    print(f"âœ… Mapa guardado en: {html_file}")

# Mapa mental con configuraciÃ³n personalizada
mind_map_config = {
    'node_spacing': 400,
    'return_data': True
}

mind_map_data = analyzer.create_interactive_mind_map(chunks, **mind_map_config)
print(f"âœ… Mapa mental generado con {len(mind_map_data['nodes'])} nodos")
```

### ğŸ”º **Ejemplo 3: TriangulaciÃ³n Avanzada**

```python
# Preparar datos de mÃºltiples fuentes
multi_source_chunks = [
    # Fuente 1: ArtÃ­culo cientÃ­fico
    {'content': 'La IA en educaciÃ³n...', 'metadata': {'source_file': 'articulo_cientifico.pdf'}},
    {'content': 'Machine learning aplicado...', 'metadata': {'source_file': 'articulo_cientifico.pdf'}},
    
    # Fuente 2: Reporte tÃ©cnico
    {'content': 'ImplementaciÃ³n de IA...', 'metadata': {'source_file': 'reporte_tecnico.pdf'}},
    {'content': 'Algoritmos de aprendizaje...', 'metadata': {'source_file': 'reporte_tecnico.pdf'}},
]

# TriangulaciÃ³n multi-fuente
triangulation = analyzer.perform_triangulation_analysis(multi_source_chunks)

print(f"ğŸ“Š Modo de anÃ¡lisis: {triangulation['analysis_mode']}")
print(f"ğŸ“š Fuentes analizadas: {triangulation['total_sources']}")
print(f"ğŸ” Conceptos totales: {triangulation['total_concepts']}")
print(f"âœ… Conceptos validados: {triangulation['validated_concepts']}")

# Mostrar conceptos mÃ¡s confiables
print("\nğŸ¯ Conceptos mÃ¡s confiables:")
for concept in triangulation['triangulated_concepts'][:5]:
    print(f"â€¢ {concept['concept']} - Confiabilidad: {concept['reliability']:.2%}")
```

### âš¡ **Ejemplo 4: AnÃ¡lisis Paralelo**

```python
from modules.qualitative_analysis import AnalysisType

# Configurar tipos de anÃ¡lisis
analysis_types = [
    AnalysisType.CONCEPT_EXTRACTION,
    AnalysisType.THEME_ANALYSIS,
    AnalysisType.SENTIMENT_ANALYSIS,
    AnalysisType.CLUSTERING
]

print("âš¡ Ejecutando anÃ¡lisis en paralelo...")
start_time = time.time()

results = analyzer.perform_parallel_analysis(chunks, analysis_types)

end_time = time.time()
print(f"âœ… AnÃ¡lisis completado en {end_time - start_time:.2f} segundos")

# Procesar resultados
for analysis_type, result in results.items():
    print(f"\nğŸ“Š {analysis_type.value}:")
    if hasattr(result, 'data'):
        print(f"   â€¢ Procesamiento exitoso")
        print(f"   â€¢ Tiempo: {result.processing_time:.2f}s")
    else:
        print(f"   â€¢ Error en procesamiento")
```

---

## ğŸ”§ Troubleshooting

### â— **Problemas Comunes**

#### **1. Error: "No hay datos disponibles"**

**Causa:** Los chunks estÃ¡n vacÃ­os o mal formateados.

**SoluciÃ³n:**
```python
# Verificar formato de chunks
for i, chunk in enumerate(chunks):
    print(f"Chunk {i}: {chunk.get('content', 'SIN CONTENIDO')[:50]}...")

# Verificar que tengan contenido
valid_chunks = [chunk for chunk in chunks if chunk.get('content', '').strip()]
print(f"Chunks vÃ¡lidos: {len(valid_chunks)}")
```

#### **2. Error: "streamlit-agraph no estÃ¡ disponible"**

**Causa:** La librerÃ­a streamlit-agraph no estÃ¡ instalada.

**SoluciÃ³n:**
```bash
pip install streamlit-agraph
```

#### **3. Error: "Error analizando jerarquÃ­a de conceptos"**

**Causa:** Problemas con el anÃ¡lisis de conceptos o memoria insuficiente.

**SoluciÃ³n:**
```python
# Reducir el nÃºmero de conceptos
concepts = analyzer.extract_key_concepts(chunks, min_freq=3)

# Limpiar cache
analyzer.clear_cache()

# Usar modo normal en lugar de IA
concept_map = analyzer.create_interactive_concept_map(chunks, layout_type="spring")
```

#### **4. Error: "Ollama no estÃ¡ disponible"**

**Causa:** El servicio Ollama no estÃ¡ ejecutÃ¡ndose.

**SoluciÃ³n:**
```bash
# Iniciar Ollama
ollama serve

# Verificar modelos disponibles
ollama list
```

#### **5. Problemas de Rendimiento**

**Causa:** Datasets muy grandes o configuraciÃ³n subÃ³ptima.

**SoluciÃ³n:**
```python
# Configurar para mejor rendimiento
config = AnalysisConfig(
    max_concepts=30,        # Reducir conceptos
    chunk_size=1500,        # Reducir tamaÃ±o de chunks
    enable_cache=True,      # Habilitar cache
    parallel_processing=True, # Procesamiento paralelo
    max_workers=2           # Reducir workers
)

analyzer = AdvancedQualitativeAnalyzer(config)

# Procesar en lotes
batch_size = 10
for i in range(0, len(chunks), batch_size):
    batch = chunks[i:i + batch_size]
    results = analyzer.extract_key_concepts(batch)
```

### ğŸ” **Debug y Logging**

```python
import logging

# Habilitar logging detallado
logging.basicConfig(level=logging.DEBUG)

# Verificar estado del cache
cache_stats = analyzer.get_cache_stats()
print(f"Cache hits: {cache_stats['hits']}")
print(f"Cache misses: {cache_stats['misses']}")
print(f"Cache size: {cache_stats['size']}")

# Verificar mÃ©tricas de rendimiento
metrics = analyzer.get_performance_metrics()
print(f"MÃ©tricas: {metrics}")
```

---

## ğŸ—ºï¸ Roadmap

### ğŸ“… **VersiÃ³n 2.1 (PrÃ³xima)**

- âœ… **API REST** para integraciÃ³n externa
- âœ… **ExportaciÃ³n** a mÃºltiples formatos (JSON, XML, CSV)
- âœ… **MÃ©tricas avanzadas** de calidad
- âœ… **Optimizaciones** de memoria

### ğŸ“… **VersiÃ³n 2.2 (Futuro)**

- ğŸ”® **IntegraciÃ³n** con bases de datos vectoriales
- ğŸ”® **AnÃ¡lisis temporal** de documentos
- ğŸ”® **Clustering automÃ¡tico** de temas
- ğŸ”® **ExportaciÃ³n** de reportes automÃ¡ticos

### ğŸ“… **VersiÃ³n 3.0 (Largo Plazo)**

- ğŸš€ **IA generativa** para resÃºmenes
- ğŸš€ **AnÃ¡lisis multimodal** (texto + imÃ¡genes)
- ğŸš€ **API GraphQL** completa
- ğŸš€ **Despliegue en la nube** escalable

---

## ğŸ“š Referencias y Recursos

### ğŸ“– **DocumentaciÃ³n TÃ©cnica**
- [GuÃ­a de Arquitectura](./ANALISIS_CUALITATIVO_ARQUITECTURA.md)
- [GuÃ­a RÃ¡pida](./ANALISIS_CUALITATIVO_GUIA_RAPIDA.md)
- [Prompt de CreaciÃ³n](./ANALISIS_CUALITATIVO_PROMPT_CREACION.md)

### ğŸ”— **Enlaces Ãštiles**
- [DocumentaciÃ³n de Streamlit](https://docs.streamlit.io/)
- [DocumentaciÃ³n de PyVis](https://pyvis.readthedocs.io/)
- [DocumentaciÃ³n de scikit-learn](https://scikit-learn.org/)

### ğŸ› ï¸ **Herramientas Relacionadas**
- **Ollama**: Modelos LLM locales
- **NLTK**: Procesamiento de lenguaje natural
- **scikit-learn**: Machine learning
- **PyVis**: Visualizaciones de redes

---

## ğŸ“„ Licencia

Este mÃ³dulo es parte del proyecto CogniChat y estÃ¡ licenciado bajo la **Licencia MIT**.

---

**Desarrollado con â¤ï¸ por el equipo de CogniChat**

*"Transformando documentos en conocimiento, una visualizaciÃ³n a la vez."* ğŸ§ âœ¨
