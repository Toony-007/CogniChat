# Optimizaciones del Sistema RAG - CogniChat

## üìã Resumen de Optimizaciones Implementadas

Este documento detalla las optimizaciones completas realizadas al sistema RAG (Retrieval-Augmented Generation) de CogniChat para mejorar el rendimiento y permitir respuestas m√°s extensas con mejor uso del contexto.

## üöÄ Mejoras de Configuraci√≥n

### Par√°metros de Generaci√≥n Optimizados
- **MAX_RESPONSE_TOKENS**: Incrementado a 3000 tokens para respuestas m√°s extensas
- **OLLAMA_TIMEOUT**: Aumentado a 120 segundos para manejar consultas complejas
- **DEFAULT_LLM_MODEL**: Optimizado para `deepseek-m1:7b` con soporte extendido

### Par√°metros RAG Optimizados
- **CHUNK_SIZE**: Incrementado a 2000 caracteres para mejor contexto
- **CHUNK_OVERLAP**: Aumentado a 300 caracteres para mayor coherencia
- **MAX_RETRIEVAL_DOCS**: Elevado a 15 documentos para contexto ampliado
- **SIMILARITY_THRESHOLD**: Reducido a 0.6 para incluir contenido m√°s relevante

## üîç Sistema de Trazabilidad Completo

### Logging de Chunks
- **Archivo**: `logs/retrieved_chunks.log`
- **Contenido**: Registro detallado de todos los chunks recuperados por consulta
- **Formato**: JSON estructurado con timestamps y metadatos

### Modo Debug Avanzado
- **Activaci√≥n**: Toggle en la interfaz de usuario
- **Informaci√≥n mostrada**:
  - Query ID √∫nico para cada consulta
  - N√∫mero de chunks recuperados
  - Caracteres de contexto utilizados
  - Documentos fuente consultados
  - Scores de similitud
  - Contenido de chunks relevantes

### Historial de Consultas
- **Archivo**: `logs/query_history.json`
- **Registro completo**:
  - Consultas realizadas
  - Respuestas generadas
  - Documentos fuente utilizados
  - Chunks asociados
  - Metadatos de procesamiento

## üìÅ Nuevos M√≥dulos Implementados

### `utils/traceability.py`
M√≥dulo central para el sistema de trazabilidad que incluye:

#### Clases Principales
- **ChunkTrace**: Estructura para informaci√≥n de chunks
- **QueryTrace**: Estructura para trazas de consultas
- **TraceabilityManager**: Gestor principal del sistema

#### Funcionalidades
- Logging autom√°tico de chunks recuperados
- Generaci√≥n de Query IDs √∫nicos
- Guardado de historial en formato JSON
- Informaci√≥n de debug estructurada

### Actualizaciones en M√≥dulos Existentes

#### `utils/rag_processor.py`
- Integraci√≥n del sistema de trazabilidad
- Funci√≥n `get_context_for_query` con soporte para tracing
- Uso de par√°metros optimizados de configuraci√≥n
- Logging autom√°tico cuando est√° habilitado

#### `utils/ollama_client.py`
- Soporte para par√°metro `max_tokens`
- Configuraciones optimizadas para DeepSeek
- Mejor manejo de timeouts

#### `modules/chatbot.py`
- Interfaz de usuario mejorada con modo debug
- Integraci√≥n completa del sistema de trazabilidad
- Configuraci√≥n de tokens en tiempo real
- Visualizaci√≥n de informaci√≥n de debug

#### `config/settings.py`
- Nuevas variables de configuraci√≥n
- Soporte para flags de trazabilidad
- Par√°metros optimizados por defecto

## üéõÔ∏è Nuevas Funcionalidades de la Interfaz

### Panel de Configuraci√≥n Expandido
1. **Modelo LLM**: Selecci√≥n din√°mica de modelos disponibles
2. **Toggle RAG**: Activaci√≥n/desactivaci√≥n del sistema RAG
3. **M√°ximo Tokens**: Control deslizante hasta 3000 tokens
4. **Modo Debug**: Activaci√≥n de informaci√≥n detallada

### Informaci√≥n de Debug en Tiempo Real
- **Estad√≠sticas de Consulta**: Query ID, chunks, caracteres, tokens
- **Documentos Fuente**: Lista de archivos consultados
- **Chunks Recuperados**: Contenido y scores de similitud
- **Metadatos de Procesamiento**: Modelo usado, configuraciones

### Historial Mejorado
- **Timestamps**: Marcas de tiempo en todos los mensajes
- **Contexto Utilizado**: Visualizaci√≥n del contexto RAG usado
- **M√©tricas del Chat**: Estad√≠sticas de uso en tiempo real

## üìä Archivos de Configuraci√≥n

### `.env` - Variables de Entorno
```env
# Configuraci√≥n Ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_TIMEOUT=120

# Modelos
DEFAULT_LLM_MODEL=deepseek-m1:7b
DEFAULT_EMBEDDING_MODEL=nomic-embed-text

# Par√°metros RAG Optimizados
CHUNK_SIZE=2000
CHUNK_OVERLAP=300
MAX_RETRIEVAL_DOCS=15
SIMILARITY_THRESHOLD=0.6

# Configuraci√≥n de Respuestas
MAX_RESPONSE_TOKENS=3000

# Sistema de Trazabilidad
ENABLE_CHUNK_LOGGING=true
ENABLE_DEBUG_MODE=true
ENABLE_HISTORY_TRACKING=true

# Otros
MAX_FILE_SIZE_MB=50
LOG_LEVEL=INFO
```

## üîß Uso del Sistema Optimizado

### 1. Carga de Documentos
- Navegar a "Procesamiento de Documentos RAG"
- Cargar documentos (PDF, DOCX, TXT, etc.)
- Procesar con par√°metros optimizados

### 2. Chat con RAG Optimizado
- Activar el toggle "Usar RAG"
- Configurar tokens m√°ximos (hasta 3000)
- Opcional: Activar modo debug para informaci√≥n detallada

### 3. An√°lisis de Trazabilidad
- Revisar `logs/retrieved_chunks.log` para chunks recuperados
- Consultar `logs/query_history.json` para historial completo
- Usar modo debug para informaci√≥n en tiempo real

## üìà Beneficios de las Optimizaciones

### Rendimiento Mejorado
- **Respuestas m√°s extensas**: Hasta 3000 tokens
- **Mejor contexto**: Chunks m√°s grandes con mayor solapamiento
- **Recuperaci√≥n ampliada**: Hasta 15 documentos por consulta

### Trazabilidad Completa
- **Transparencia total**: Visibilidad completa del proceso RAG
- **Debug avanzado**: Informaci√≥n detallada para optimizaci√≥n
- **Historial persistente**: Registro completo de todas las interacciones

### Experiencia de Usuario
- **Interfaz mejorada**: Controles intuitivos y informaci√≥n clara
- **Feedback en tiempo real**: Estad√≠sticas y m√©tricas visibles
- **Flexibilidad**: Configuraci√≥n adaptable seg√∫n necesidades

## üîÑ Compatibilidad

Todas las optimizaciones mantienen **compatibilidad completa** con:
- Estructura existente del proyecto
- M√≥dulos `document_processor.py` y `chatbot.py`
- Flujo de trabajo actual
- Configuraciones previas

## üìù Notas T√©cnicas

### Archivos de Log
- Los logs se crean autom√°ticamente en el directorio `logs/`
- Formato JSON para f√°cil procesamiento
- Rotaci√≥n autom√°tica para evitar archivos grandes

### Configuraci√≥n Din√°mica
- Cambios en `.env` requieren reinicio de la aplicaci√≥n
- Configuraciones de UI se aplican inmediatamente
- Modo debug se puede activar/desactivar en tiempo real

### Optimizaci√≥n para DeepSeek
- Prompts optimizados para razonamiento profundo
- Contexto completo para an√°lisis comprehensivo
- Configuraciones espec√≠ficas para mejor rendimiento