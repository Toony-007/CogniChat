"""
Funci√≥n Principal de Renderizado
Integraci√≥n con la aplicaci√≥n principal (app.py)
"""

import streamlit as st
from typing import List, Dict, Any

from ..core.config import AnalysisConfig
from ..core.analyzer import QualitativeAnalyzer
from ..core.rag_cache_manager import RAGCacheManager
from .tabs.concepts_tab import render_concepts_tab
from .tabs.topics_tab import render_topics_tab
from .tabs.relations_tab import render_relations_tab
from .components.cache_management import render_cache_management_panel


def render():
    """
    Funci√≥n principal de renderizado del m√≥dulo de an√°lisis cualitativo
    
    Esta funci√≥n se llama desde app.py y mantiene compatibilidad con la estructura actual.
    
    Renderiza:
    1. Introducci√≥n al sistema
    2. Detecci√≥n autom√°tica de rag_cache.json
    3. Verificaci√≥n de documentos disponibles
    4. Tabs para cada sub-m√≥dulo de an√°lisis
    """
    
    # Header principal
    st.markdown("""
    <div style="
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 10px;
        margin-bottom: 2rem;
        text-align: center;
    ">
        <h1 style="color: white; margin: 0; font-size: 2.5rem;">üî¨ An√°lisis Cualitativo Avanzado</h1>
        <p style="color: white; margin: 0.5rem 0 0 0; font-size: 1.2rem; opacity: 0.95;">
            Sistema Inteligente de An√°lisis de Contenido para Investigaci√≥n
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # Introducci√≥n y principios
    with st.expander("‚ÑπÔ∏è Acerca de este M√≥dulo", expanded=False):
        st.markdown("""
        ### üéØ Principios Fundamentales
        
        Este sistema ha sido dise√±ado espec√≠ficamente para **asistir a investigadores**
        en el an√°lisis profundo de contenido, siguiendo estos principios:
        
        #### 1. üß≠ Asistencia al Investigador
        - Explicaciones claras sobre qu√© hace cada an√°lisis
        - Gu√≠as de interpretaci√≥n de resultados
        - Informaci√≥n sobre metodolog√≠as utilizadas
        
        #### 2. üß† Procesamiento Inteligente
        - **NO copia y pega** informaci√≥n de las fuentes
        - Analiza, sintetiza y contextualiza el contenido
        - Genera valor a√±adido mediante procesamiento inteligente
        
        #### 3. üìö Fundamentaci√≥n Completa
        - Cada resultado est√° respaldado por citas a fuentes originales
        - Sistema de citaci√≥n que permite verificar de d√≥nde viene cada informaci√≥n
        - Trazabilidad completa del an√°lisis
        
        #### 4. üî¨ Transparencia Metodol√≥gica
        - Algoritmos y t√©cnicas claramente documentados
        - Limitaciones y consideraciones expl√≠citas
        - Validaci√≥n humana siempre recomendada
        
        ### üìã Sub-m√≥dulos Disponibles
        
        **Actualmente implementado:**
        - ‚úÖ **Extracci√≥n de Conceptos Clave**: Identifica t√©rminos y frases m√°s relevantes con TF-IDF
        
        **En desarrollo futuro:**
        - üîú **An√°lisis de Temas**: Identificaci√≥n de temas principales con LDA
        - üîú **Triangulaci√≥n**: Validaci√≥n cruzada entre m√∫ltiples fuentes
        - üîú **Mapas Conceptuales**: Visualizaci√≥n de relaciones entre conceptos
        - üîú **An√°lisis de Relaciones**: Identificaci√≥n de conexiones y patrones
        
        ### üéì C√≥mo Usar Este Sistema
        
        1. **Prepara tus documentos**: Sube y procesa tus archivos en las pesta√±as anteriores
        2. **Selecciona un an√°lisis**: Elige el tipo de an√°lisis que necesitas
        3. **Lee la metodolog√≠a**: Entiende c√≥mo funciona el an√°lisis antes de ejecutarlo
        4. **Ejecuta el an√°lisis**: Configura par√°metros y ejecuta
        5. **Interpreta resultados**: Usa las gu√≠as de interpretaci√≥n proporcionadas
        6. **Verifica fuentes**: Revisa las citas para validar los resultados
        7. **Exporta datos**: Guarda los resultados para tu investigaci√≥n
        
        ### ‚ö†Ô∏è Importante
        
        Este sistema es una **herramienta de asistencia**, no un reemplazo del an√°lisis humano.
        Los resultados deben ser:
        - ‚úÖ Revisados por el investigador
        - ‚úÖ Validados con el conocimiento experto del dominio
        - ‚úÖ Contextualizados seg√∫n los objetivos de la investigaci√≥n
        - ‚úÖ Complementados con an√°lisis cualitativo manual cuando sea necesario
        """)
    
    # Inicializar gestor de cache RAG
    cache_manager = RAGCacheManager()
    
    # Detectar cache autom√°ticamente
    st.markdown("### üîç Detecci√≥n Autom√°tica de Cache RAG")
    cache_manager.render_cache_status()
    
    st.divider()
    
    # Obtener chunks de documentos procesados
    chunks = _get_processed_chunks_with_cache(cache_manager)
    
    # Verificar si hay documentos disponibles
    if not chunks:
        st.warning("""
        ### ‚ö†Ô∏è No hay documentos disponibles para an√°lisis
        
        Para usar este m√≥dulo, primero debes:
        
        1. **üìÑ Gesti√≥n de Documentos**: Sube tus archivos (PDF, DOCX, TXT, etc.)
        2. **üß† Procesamiento RAG**: Procesa los documentos para crear chunks
        3. **üî¨ An√°lisis Cualitativo**: Regresa aqu√≠ para realizar an√°lisis
        
        Una vez que hayas procesado tus documentos, podr√°s:
        - Extraer conceptos clave
        - Analizar temas y patrones
        - Generar visualizaciones
        - Obtener citas y referencias
        """)
        
        # Mostrar bot√≥n para ir a gesti√≥n de documentos
        col1, col2, col3 = st.columns([2, 1, 2])
        with col2:
            if st.button("üìÑ Ir a Gesti√≥n de Documentos", type="primary", use_container_width=True):
                st.info("Por favor, usa las pesta√±as en la parte superior para navegar")
        
        return
    
    # Informaci√≥n sobre documentos disponibles
    st.success(f"""
    ‚úÖ **{len(chunks)} fragmentos de texto disponibles** de {len(_get_unique_sources(chunks))} documento(s)
    """)
    
    # Inicializar configuraci√≥n en session_state si no existe
    if 'qualitative_analysis_config' not in st.session_state:
        st.session_state.qualitative_analysis_config = AnalysisConfig()
    
    config = st.session_state.qualitative_analysis_config
    
    # Configuraci√≥n global en sidebar
    with st.sidebar:
        st.markdown("### ‚öôÔ∏è Configuraci√≥n Global")
        
        with st.expander("üéõÔ∏è Opciones de Interfaz", expanded=False):
            config.show_explanations = st.checkbox(
                "Mostrar explicaciones",
                value=config.show_explanations,
                help="Mostrar cajas informativas sobre c√≥mo funciona cada an√°lisis"
            )
            
            config.show_methodology = st.checkbox(
                "Mostrar metodolog√≠a",
                value=config.show_methodology,
                help="Mostrar detalles t√©cnicos sobre algoritmos utilizados"
            )
            
            config.show_interpretation_guide = st.checkbox(
                "Mostrar gu√≠as de interpretaci√≥n",
                value=config.show_interpretation_guide,
                help="Mostrar gu√≠as sobre c√≥mo interpretar resultados"
            )
            
            config.enable_citations = st.checkbox(
                "Habilitar citaci√≥n",
                value=config.enable_citations,
                help="Generar citas a fuentes originales"
            )
        
        # Informaci√≥n de ayuda
        st.markdown("---")
        st.markdown("### üí° Ayuda R√°pida")
        
        st.markdown("""
        **Funcionalidades Implementadas:**
        - üîç **Conceptos Clave**: Identifica t√©rminos importantes con TF-IDF
        - üéØ **An√°lisis de Temas**: Extrae temas principales usando LDA
        - üîó **An√°lisis de Relaciones**: Descubre conexiones entre conceptos
        - üìö **Sistema de Citaci√≥n**: Referencias a fuentes originales
        - üîß **Gesti√≥n de Cache**: Optimizaci√≥n de rendimiento
        """)
    
    # Tabs para diferentes sub-m√≥dulos (orden l√≥gico de an√°lisis)
    tabs = st.tabs([
        "üîß Gesti√≥n de Cache",
        "üîç Conceptos Clave",
        "üéØ An√°lisis de Temas", 
        "üîó An√°lisis de Relaciones"
    ])
    
    # Tab 1: Gesti√≥n de Cache (IMPLEMENTADO)
    with tabs[0]:
        render_cache_management_panel()
    
    # Tab 2: Extracci√≥n de Conceptos (IMPLEMENTADO)
    with tabs[1]:
        render_concepts_tab(chunks, config)
    
    # Tab 3: An√°lisis de Temas (IMPLEMENTADO)
    with tabs[2]:
        render_topics_tab(chunks, config)
    
    # Tab 4: An√°lisis de Relaciones (IMPLEMENTADO)
    with tabs[3]:
        render_relations_tab(chunks, config)


def _get_processed_chunks_with_cache(cache_manager: RAGCacheManager) -> List[Dict[str, Any]]:
    """
    Obtener chunks procesados de documentos con detecci√≥n autom√°tica de cache
    
    Args:
        cache_manager: Gestor de cache RAG
        
    Returns:
        Lista de chunks con contenido y metadatos
    """
    try:
        # Prioridad 1: Intentar obtener del cache RAG
        chunks = cache_manager.get_chunks_for_analysis()
        if chunks:
            st.info(f"‚úÖ Chunks obtenidos del cache RAG: {len(chunks)} fragmentos")
            return chunks
        
        # Prioridad 2: Intentar obtener del procesador RAG
        from utils.rag_processor import rag_processor
        
        if hasattr(rag_processor, 'vector_store') and rag_processor.vector_store:
            all_chunks = []
            
            try:
                # Hacer una b√∫squeda amplia para obtener todos los chunks
                results = rag_processor.search("", top_k=1000)
                
                for result in results:
                    chunk = {
                        'content': result.get('content', ''),
                        'metadata': result.get('metadata', {})
                    }
                    
                    # Asegurar que metadata tenga source_file
                    if 'source_file' not in chunk['metadata']:
                        chunk['metadata']['source_file'] = 'unknown'
                    
                    all_chunks.append(chunk)
                
                if all_chunks:
                    st.info(f"‚úÖ Chunks obtenidos del procesador RAG: {len(all_chunks)} fragmentos")
                    return all_chunks
                
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Error al obtener chunks del procesador RAG: {str(e)}")
        
        # Prioridad 3: Buscar en session_state
        if 'processed_chunks' in st.session_state:
            chunks = st.session_state.processed_chunks
            if chunks:
                st.info(f"‚úÖ Chunks obtenidos de session_state: {len(chunks)} fragmentos")
                return chunks
        
        # Si no hay chunks, retornar lista vac√≠a
        return []
    
    except Exception as e:
        st.error(f"‚ùå Error al obtener chunks: {str(e)}")
        return []


def _get_processed_chunks() -> List[Dict[str, Any]]:
    """
    Obtener chunks procesados de documentos (m√©todo legacy)
    
    Returns:
        Lista de chunks con contenido y metadatos
    """
    try:
        # Importar el procesador RAG
        from utils.rag_processor import rag_processor
        
        # Obtener todos los chunks del procesador
        if hasattr(rag_processor, 'vector_store') and rag_processor.vector_store:
            # Si hay vector store, obtener chunks desde ah√≠
            all_chunks = []
            
            # Intentar obtener chunks de la base de datos vectorial
            try:
                # Hacer una b√∫squeda amplia para obtener todos los chunks
                results = rag_processor.search("", top_k=1000)
                
                for result in results:
                    chunk = {
                        'content': result.get('content', ''),
                        'metadata': result.get('metadata', {})
                    }
                    
                    # Asegurar que metadata tenga source_file
                    if 'source_file' not in chunk['metadata']:
                        chunk['metadata']['source_file'] = 'unknown'
                    
                    all_chunks.append(chunk)
                
                return all_chunks
            
            except:
                pass
        
        # Fallback: Buscar en session_state
        if 'processed_chunks' in st.session_state:
            return st.session_state.processed_chunks
        
        # Si no hay chunks, retornar lista vac√≠a
        return []
    
    except Exception as e:
        st.error(f"Error al obtener chunks: {str(e)}")
        return []


def _get_unique_sources(chunks: List[Dict[str, Any]]) -> List[str]:
    """
    Obtener lista de fuentes √∫nicas
    
    Args:
        chunks: Lista de chunks
        
    Returns:
        Lista de nombres de archivos fuente √∫nicos
    """
    sources = set()
    for chunk in chunks:
        source = chunk.get('metadata', {}).get('source_file', 'unknown')
        sources.add(source)
    
    return list(sources)

