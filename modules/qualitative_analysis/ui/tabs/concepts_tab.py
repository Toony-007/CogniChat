"""
Tab de Extracci√≥n de Conceptos Clave
Primer sub-m√≥dulo del sistema de an√°lisis cualitativo
"""

import streamlit as st
from typing import List, Dict, Any
import json
from datetime import datetime

from ...extractors.concept_extractor import ConceptExtractor, ExtractedConcept
from ...core.config import AnalysisConfig
from ..components.educational import (
    show_methodology_box,
    show_interpretation_guide,
    show_concept_card,
    show_statistics_panel,
    show_help_sidebar
)


def render_concepts_tab(chunks: List[Dict[str, Any]], config: AnalysisConfig):
    """
    Renderizar tab de extracci√≥n de conceptos clave
    
    Args:
        chunks: Lista de chunks de documentos
        config: Configuraci√≥n del an√°lisis
    """
    
    # T√≠tulo con descripci√≥n
    st.markdown("""
    <div style="
        background: linear-gradient(90deg, #00FF99 0%, #00CC7A 100%);
        padding: 1.5rem;
        border-radius: 10px;
        margin-bottom: 2rem;
        text-align: center;
    ">
        <h1 style="color: white; margin: 0; font-size: 2rem;">üîç Extracci√≥n de Conceptos Clave</h1>
        <p style="color: white; margin: 0.5rem 0 0 0; font-size: 1.1rem; opacity: 0.9;">
            Identifica los conceptos m√°s importantes de tus documentos con fundamentaci√≥n completa
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # Mostrar ayuda en sidebar
    show_help_sidebar()
    
    # Mostrar metodolog√≠a si est√° habilitado
    if config.show_methodology:
        methodology_title = "Enfoque H√≠brido: TF-IDF + DeepSeek R1" if config.enable_llm_refinement else "Extracci√≥n Inteligente con TF-IDF"
        
        methodology_description = """
            Este an√°lisis identifica los **conceptos m√°s relevantes** de tus documentos
            usando un **enfoque h√≠brido** que combina:
            
            - **TF-IDF** (Term Frequency-Inverse Document Frequency) para extracci√≥n inicial
            - **DeepSeek R1** para refinamiento y mejora de conceptos
            
            El proceso identifica t√©rminos que son:
            - **Frecuentes** en documentos espec√≠ficos (TF - Term Frequency)
            - **Raros** en el corpus general (IDF - Inverse Document Frequency)
            - **Refinados** por IA para generar conceptos acad√©micos profundos
            """ if config.enable_llm_refinement else """
            Este an√°lisis identifica los **conceptos m√°s relevantes** de tus documentos
            usando **TF-IDF** (Term Frequency-Inverse Document Frequency), una t√©cnica
            est√°ndar en an√°lisis de textos que identifica t√©rminos que son:
            
            - **Frecuentes** en documentos espec√≠ficos (TF - Term Frequency)
            - **Raros** en el corpus general (IDF - Inverse Document Frequency)
            
            Esto permite encontrar conceptos que son **importantes y distintivos**.
            """
        
        methodology_steps = [
            "**Preprocesamiento**: Limpia el texto, elimina palabras vac√≠as (stopwords) y normaliza",
            "**Vectorizaci√≥n**: Convierte el texto en representaci√≥n matem√°tica usando TF-IDF",
            "**Extracci√≥n inicial**: Identifica t√©rminos individuales y frases completas (n-gramas)",
            "**Puntuaci√≥n**: Calcula un score de relevancia para cada concepto (0.0 a 1.0)",
            "**ü§ñ Refinamiento IA**: DeepSeek R1 analiza y mejora los conceptos candidatos",
            "**Generaci√≥n de conceptos profundos**: Crea conceptos acad√©micos significativos",
            "**Citaci√≥n**: Identifica y registra todas las fuentes donde aparece cada concepto",
            "**An√°lisis de relaciones**: Identifica conceptos que aparecen juntos frecuentemente",
            "**Ordenamiento**: Presenta los conceptos ordenados por relevancia"
        ] if config.enable_llm_refinement else [
            "**Preprocesamiento**: Limpia el texto, elimina palabras vac√≠as (stopwords) y normaliza",
            "**Vectorizaci√≥n**: Convierte el texto en representaci√≥n matem√°tica usando TF-IDF",
            "**Extracci√≥n**: Identifica t√©rminos individuales y frases completas (n-gramas)",
            "**Puntuaci√≥n**: Calcula un score de relevancia para cada concepto (0.0 a 1.0)",
            "**Citaci√≥n**: Identifica y registra todas las fuentes donde aparece cada concepto",
            "**An√°lisis de relaciones**: Identifica conceptos que aparecen juntos frecuentemente",
            "**Ordenamiento**: Presenta los conceptos ordenados por relevancia"
        ]
        
        algorithm_info = "TF-IDF + DeepSeek R1 para conceptos acad√©micos profundos" if config.enable_llm_refinement else "TF-IDF con detecci√≥n de n-gramas (frases de 1-3 palabras)"
        
        show_methodology_box(
            title=methodology_title,
            description=methodology_description,
            steps=methodology_steps,
            algorithm_info=algorithm_info
        )
    
    # Mostrar gu√≠a de interpretaci√≥n si est√° habilitado
    if config.show_interpretation_guide:
        what_it_means = """
            Los **conceptos extra√≠dos** representan las ideas centrales y t√©rminos t√©cnicos
            m√°s importantes en tus documentos. El **score de relevancia** indica qu√© tan
            caracter√≠stico es cada concepto del contenido analizado.
            
            Los conceptos con mayor score son aquellos que:
            - Aparecen frecuentemente en tus documentos
            - Son espec√≠ficos de tu contenido (no son palabras comunes)
            - Est√°n bien distribuidos en las fuentes
            """ if not config.enable_llm_refinement else """
            Los **conceptos extra√≠dos** son ideas acad√©micas profundas y significativas
            que emergen de tus documentos. El **score de relevancia** indica qu√© tan
            caracter√≠stico es cada concepto del contenido analizado.
            
            Con el refinamiento IA, los conceptos son:
            - **Acad√©micos y profundos**: Capturan procesos, relaciones y fen√≥menos complejos
            - **Espec√≠ficos al contexto**: Explican "c√≥mo" y "por qu√©", no solo "qu√©"
            - **Fundamentados**: Incluyen explicaciones y categorizaci√≥n autom√°tica
            - **Significativos**: Eliminan palabras gen√©ricas y letras sueltas
            """
        
        how_to_use = [
            "Identifica los temas principales de tu corpus documental",
            "Verifica que los conceptos extra√≠dos coinciden con tu comprensi√≥n del contenido",
            "Usa las citas para volver a las fuentes originales y profundizar",
            "Examina los conceptos relacionados para entender conexiones tem√°ticas",
            "Compara la distribuci√≥n de conceptos entre diferentes fuentes",
            "Usa estos conceptos como base para an√°lisis posteriores (temas, relaciones, etc.)"
        ] if not config.enable_llm_refinement else [
            "Identifica los fen√≥menos centrales de tu investigaci√≥n",
            "Analiza las explicaciones generadas por la IA para cada concepto",
            "Examina las categor√≠as asignadas (metodolog√≠a, teor√≠a, resultado, etc.)",
            "Usa las citas para volver a las fuentes originales y validar",
            "Estudia las relaciones entre conceptos para entender patrones complejos",
            "Aprovecha los conceptos profundos para desarrollar marcos te√≥ricos",
            "Utiliza las explicaciones para fundamentar tu an√°lisis cualitativo"
        ]
        
        limitations = [
            "El sistema identifica palabras y frases frecuentes, pero no comprende significado",
            "Conceptos muy espec√≠ficos con baja frecuencia pueden no aparecer",
            "La relevancia es estad√≠stica, no sem√°ntica (requiere validaci√≥n del investigador)",
            "T√©rminos polis√©micos (m√∫ltiples significados) no se distinguen autom√°ticamente",
            "La calidad depende de la calidad y cantidad de documentos analizados"
        ] if not config.enable_llm_refinement else [
            "Los conceptos generados por IA requieren validaci√≥n del investigador",
            "La calidad depende de la calidad y cantidad de documentos analizados",
            "El LLM puede generar conceptos que no est√°n directamente en el texto",
            "Las explicaciones son interpretaciones que deben ser verificadas",
            "La categorizaci√≥n autom√°tica puede no ser perfecta",
            "Requiere acceso a un modelo LLM (Ollama) para funcionar"
        ]
        
        show_interpretation_guide(
            what_it_means=what_it_means,
            how_to_use=how_to_use,
            limitations=limitations
        )
    
    # Verificar que hay documentos
    if not chunks:
        st.warning("""
        ‚ö†Ô∏è **No hay documentos para analizar**
        
        Por favor, ve a la pesta√±a **"üìÑ Gesti√≥n de Documentos"** para:
        1. Subir documentos (PDF, DOCX, TXT, etc.)
        2. Luego ve a **"üß† Procesamiento RAG"** para procesar los documentos
        3. Vuelve aqu√≠ para realizar el an√°lisis cualitativo
        """)
        return
    
    # Informaci√≥n sobre los documentos
    st.markdown("### üìÇ Documentos Disponibles")
    
    sources = list(set(chunk['metadata'].get('source_file', 'unknown') for chunk in chunks))
    total_content = sum(len(chunk.get('content', '')) for chunk in chunks)
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("üìÑ Documentos", len(sources))
    with col2:
        st.metric("üìù Chunks", len(chunks))
    with col3:
        st.metric("üìä Caracteres", f"{total_content:,}")
    
    with st.expander("üìã Ver lista de fuentes"):
        for i, source in enumerate(sources, 1):
            st.markdown(f"{i}. `{source}`")
    
    st.divider()
    
    # Configuraci√≥n del an√°lisis (valores predefinidos en el c√≥digo)
    st.markdown("### ‚öôÔ∏è Configuraci√≥n del An√°lisis")
    
    st.info("""
    **‚ÑπÔ∏è Configuraci√≥n Autom√°tica:** Los par√°metros del an√°lisis est√°n optimizados autom√°ticamente.
    Si necesitas modificar alg√∫n par√°metro espec√≠fico, puedes hacerlo directamente en el c√≥digo.
    """)
    
    st.divider()
    
    # Configuraci√≥n de categor√≠as iniciales
    st.markdown("#### üè∑Ô∏è Categor√≠as Iniciales (Opcional)")
    
    use_custom_categories = st.checkbox(
        "Usar categor√≠as iniciales personalizadas",
        value=config.use_custom_categories,
        help="Define categor√≠as espec√≠ficas para dirigir la extracci√≥n de conceptos",
        key="concepts_use_custom_categories"
    )
    
    if use_custom_categories:
        st.markdown("**Define las categor√≠as que necesitas identificar en tu investigaci√≥n:**")
        
        # Inicializar categor√≠as en session state si no existen
        if 'custom_categories' not in st.session_state:
            st.session_state.custom_categories = config.custom_categories.copy()
        
        # Mostrar categor√≠as existentes
        categories_to_remove = []
        for i, (category, definition) in enumerate(st.session_state.custom_categories.items()):
            with st.expander(f"üìÇ {category}", expanded=True):
                col1, col2 = st.columns([3, 1])
                
                with col1:
                    new_category = st.text_input(
                        f"Categor√≠a {i+1}",
                        value=category,
                        key=f"concepts_category_{i}",
                        help="Nombre de la categor√≠a (ej: Metodolog√≠a de investigaci√≥n)"
                    )
                    
                    new_definition = st.text_area(
                        f"Definici√≥n {i+1}",
                        value=definition,
                        key=f"concepts_definition_{i}",
                        height=100,
                        help="Descripci√≥n detallada de qu√© incluye esta categor√≠a"
                    )
                
                with col2:
                    if st.button("üóëÔ∏è", key=f"concepts_remove_{i}", help="Eliminar categor√≠a"):
                        categories_to_remove.append(category)
                
                # Actualizar categor√≠a si cambi√≥
                if new_category != category or new_definition != definition:
                    if new_category and new_definition:
                        # Eliminar la antigua
                        if category in st.session_state.custom_categories:
                            del st.session_state.custom_categories[category]
                        # Agregar la nueva
                        st.session_state.custom_categories[new_category] = new_definition
                        st.rerun()
        
        # Eliminar categor√≠as marcadas para eliminaci√≥n
        for category in categories_to_remove:
            if category in st.session_state.custom_categories:
                del st.session_state.custom_categories[category]
                st.rerun()
        
        # Bot√≥n para agregar nueva categor√≠a
        if st.button("‚ûï Agregar Nueva Categor√≠a", type="secondary", key="concepts_add_category"):
            new_key = f"new_category_{len(st.session_state.custom_categories)}"
            st.session_state.custom_categories[new_key] = ""
            st.rerun()
        
        # Mostrar resumen
        if st.session_state.custom_categories:
            st.success(f"‚úÖ {len(st.session_state.custom_categories)} categor√≠as definidas")
            with st.expander("üìã Ver resumen de categor√≠as"):
                for category, definition in st.session_state.custom_categories.items():
                    st.markdown(f"**{category}:** {definition[:100]}{'...' if len(definition) > 100 else ''}")
        else:
            st.info("üí° Agrega al menos una categor√≠a para dirigir la extracci√≥n de conceptos")
    
    st.divider()
    
    # Actualizar configuraci√≥n (solo categor√≠as personalizadas)
    config.use_custom_categories = use_custom_categories
    
    # Actualizar categor√≠as personalizadas si est√°n habilitadas
    if use_custom_categories and 'custom_categories' in st.session_state:
        config.custom_categories = st.session_state.custom_categories.copy()
    
    st.divider()
    
    # Botones de an√°lisis
    col1, col2, col3 = st.columns([2, 1, 2])
    
    with col1:
        if st.session_state.get('concepts_extracted', False):
            if st.button("üîÑ Nuevo An√°lisis", type="secondary", use_container_width=True, help="Limpiar resultados y realizar nuevo an√°lisis", key="concepts_new_analysis"):
                # Limpiar session state
                st.session_state.concepts_extracted = False
                st.session_state.extracted_concepts = None
                st.session_state.concept_extractor = None
                st.session_state.concepts_summary = None
                st.rerun()
    
    with col2:
        if not st.session_state.get('concepts_extracted', False):
            analyze_button = st.button(
                "üöÄ Extraer Conceptos",
                type="primary",
                use_container_width=True,
                help="Iniciar an√°lisis de extracci√≥n de conceptos",
                key="concepts_analyze"
            )
        else:
            analyze_button = False
    
    with col3:
        if st.session_state.get('concepts_extracted', False):
            st.success("‚úÖ An√°lisis completado")
    
    # Realizar an√°lisis solo si se presiona el bot√≥n Y no hay resultados previos
    if analyze_button and not st.session_state.get('concepts_extracted', False):
        
        # Mostrar spinner durante an√°lisis
        with st.spinner("üîç Analizando documentos y extrayendo conceptos..."):
            try:
                # Crear extractor
                extractor = ConceptExtractor(config)
                
                # Extraer conceptos
                concepts = extractor.extract_concepts(chunks, method='tfidf')
                
                # Guardar en session state
                st.session_state.concepts_extracted = True
                st.session_state.extracted_concepts = concepts
                st.session_state.concept_extractor = extractor
                
                # Obtener resumen
                summary = extractor.get_concept_summary(concepts)
                st.session_state.concepts_summary = summary
                
                # Forzar re-ejecuci√≥n para mostrar resultados
                st.rerun()
                
            except Exception as e:
                st.error(f"‚ùå **Error en el an√°lisis:** {str(e)}")
                st.exception(e)
                return
    
    # Mostrar resultados si ya est√°n disponibles
    if st.session_state.get('concepts_extracted', False):
        # Obtener datos de session state
        concepts = st.session_state.extracted_concepts
        extractor = st.session_state.concept_extractor
        summary = st.session_state.concepts_summary
        
        # Mostrar resultados
        st.success(f"‚úÖ **An√°lisis completado:** {len(concepts)} conceptos extra√≠dos")
        
        st.divider()
        
        # Panel de estad√≠sticas
        show_statistics_panel(summary)
        
        st.divider()
        
        # Tabs para diferentes vistas
        tab1, tab2, tab3, tab4 = st.tabs([
            "üéØ Conceptos Principales",
            "üîó Relaciones",
            "üìö Bibliograf√≠a",
            "üíæ Exportar"
        ])
        
        # Tab 1: Conceptos principales
        with tab1:
            st.markdown("### üéØ Conceptos Clave Identificados")
            
            st.markdown("""
            <div style="background: #34495e; padding: 1rem; border-radius: 8px; border-left: 4px solid #00FF99; color: #ecf0f1; margin: 1rem 0;">
                <strong>‚ÑπÔ∏è Interpretaci√≥n:</strong> Los conceptos est√°n ordenados por relevancia. 
                Los primeros son los m√°s caracter√≠sticos de tu corpus documental.
                Cada concepto incluye <strong>citas a las fuentes originales</strong> para fundamentaci√≥n.
            </div>
            """, unsafe_allow_html=True)
            
            # Filtros
            col1, col2 = st.columns([3, 1])
            with col1:
                filter_text = st.text_input(
                    "üîç Filtrar conceptos",
                    placeholder="Escribe para buscar...",
                    help="Filtra los conceptos por texto",
                    key="concepts_filter_text"
                )
            with col2:
                sort_by = st.selectbox(
                    "Ordenar por",
                    ["Relevancia", "Frecuencia", "Nombre"],
                    help="Criterio de ordenamiento",
                    key="concepts_sort_by"
                )
            
            # Aplicar filtros
            filtered_concepts = concepts
            if filter_text:
                filtered_concepts = [
                    c for c in concepts
                    if filter_text.lower() in c.concept.lower()
                ]
            
            # Ordenar
            if sort_by == "Frecuencia":
                filtered_concepts = sorted(filtered_concepts, key=lambda c: c.frequency, reverse=True)
            elif sort_by == "Nombre":
                filtered_concepts = sorted(filtered_concepts, key=lambda c: c.concept)
            
            # Paginaci√≥n
            concepts_per_page = 10
            total_pages = (len(filtered_concepts) + concepts_per_page - 1) // concepts_per_page
            
            if total_pages > 1:
                col1, col2, col3 = st.columns([2, 1, 2])
                with col2:
                    page = st.selectbox(
                        "P√°gina",
                        range(1, total_pages + 1),
                        format_func=lambda x: f"P√°gina {x} de {total_pages}",
                        key="concepts_page_selector"
                    )
            else:
                page = 1
            
            # Calcular rango
            start_idx = (page - 1) * concepts_per_page
            end_idx = min(start_idx + concepts_per_page, len(filtered_concepts))
            
            # Mostrar conceptos
            st.markdown(f"**Mostrando {start_idx + 1}-{end_idx} de {len(filtered_concepts)} conceptos**")
            
            for i, concept in enumerate(filtered_concepts[start_idx:end_idx], start=start_idx + 1):
                show_concept_card(
                    concept=concept,
                    rank=i,
                    show_citations=config.enable_citations,
                    show_related=True
                )
        
        # Tab 2: Relaciones entre conceptos
        with tab2:
            st.markdown("### üîó Relaciones entre Conceptos")
            
            st.markdown("""
            <div style="background: #34495e; padding: 1rem; border-radius: 8px; border-left: 4px solid #3498db; color: #ecf0f1; margin: 1rem 0;">
                <strong>‚ÑπÔ∏è Sobre las relaciones:</strong> Los conceptos relacionados son aquellos que
                aparecen frecuentemente juntos en los mismos fragmentos de texto. Esto puede indicar
                conexiones tem√°ticas importantes.
            </div>
            """, unsafe_allow_html=True)
            
            # Seleccionar concepto para ver relaciones
            concept_names = [c.concept for c in concepts[:30]]  # Top 30
            selected_concept_name = st.selectbox(
                "Selecciona un concepto para ver sus relaciones",
                concept_names,
                help="Muestra conceptos que co-ocurren con el seleccionado",
                key="concepts_relation_selector"
            )
            
            # Encontrar concepto seleccionado
            selected_concept = next(c for c in concepts if c.concept == selected_concept_name)
            
            # Mostrar informaci√≥n del concepto
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.markdown(f"### üìå {selected_concept.concept}")
                st.markdown(f"""
                - **Frecuencia:** {selected_concept.frequency}
                - **Relevancia:** {selected_concept.relevance_score:.3f}
                - **Fuentes:** {len(selected_concept.sources)}
                """)
            
            with col2:
                st.metric(
                    "üîó Conceptos Relacionados",
                    len(selected_concept.related_concepts)
                )
            
            # Mostrar conceptos relacionados
            if selected_concept.related_concepts:
                st.markdown("#### Conceptos que aparecen junto a este:")
                
                for i, related_name in enumerate(selected_concept.related_concepts, 1):
                    # Encontrar informaci√≥n del concepto relacionado
                    related_concept = next((c for c in concepts if c.concept == related_name), None)
                    
                    if related_concept:
                        st.markdown(f"""
                        <div style="background: #2c3e50; padding: 0.8rem; border-radius: 5px; margin: 0.5rem 0; border-left: 3px solid #3498db; color: #ecf0f1;">
                            <strong>{i}. {related_concept.concept}</strong><br>
                            <small>Frecuencia: {related_concept.frequency} | Relevancia: {related_concept.relevance_score:.3f}</small>
                        </div>
                        """, unsafe_allow_html=True)
            else:
                st.info("Este concepto no tiene relaciones fuertes identificadas")
            
            # Matriz de co-ocurrencia (simplificada)
            st.markdown("---")
            st.markdown("#### üìä Matriz de Co-ocurrencia (Top 10)")
            
            # Crear matriz simple
            top_10 = concepts[:10]
            matrix_data = []
            
            for concept in top_10:
                row = {
                    'Concepto': concept.concept,
                    'Relaciones': len(concept.related_concepts)
                }
                matrix_data.append(row)
            
            st.dataframe(matrix_data, use_container_width=True)
        
        # Tab 3: Bibliograf√≠a
        with tab3:
            st.markdown("### üìö Bibliograf√≠a y Referencias")
            
            st.markdown("""
            <div style="background: #34495e; padding: 1rem; border-radius: 8px; border-left: 4px solid #9b59b6; color: #ecf0f1; margin: 1rem 0;">
                <strong>‚ÑπÔ∏è Fundamentaci√≥n cient√≠fica:</strong> Cada concepto est√° respaldado por citas
                espec√≠ficas a las fuentes originales. Esta secci√≥n te permite ver todas las referencias
                y verificar la fundamentaci√≥n del an√°lisis.
            </div>
            """, unsafe_allow_html=True)
            
            # Estad√≠sticas de citaci√≥n
            cit_stats = extractor.citation_manager.get_statistics()
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("üìñ Total de Citas", cit_stats['total_citations'])
            with col2:
                st.metric("üìÇ Fuentes Citadas", cit_stats['unique_sources'])
            with col3:
                st.metric("‚≠ê Relevancia Promedio", f"{cit_stats['avg_relevance']:.3f}")
            
            # Bibliograf√≠a
            st.markdown("#### üìã Referencias Bibliogr√°ficas")
            
            bibliography = extractor.citation_manager.generate_bibliography()
            
            for i, ref in enumerate(bibliography, 1):
                st.markdown(f"{i}. {ref}")
            
            # Distribuci√≥n de citas por fuente
            if 'citations_by_source' in cit_stats:
                st.markdown("---")
                st.markdown("#### üìä Distribuci√≥n de Citas por Fuente")
                
                import plotly.graph_objects as go
                
                sources_list = list(cit_stats['citations_by_source'].keys())
                counts = list(cit_stats['citations_by_source'].values())
                
                # Truncar nombres largos
                sources_display = [s.split('/')[-1][:30] for s in sources_list]
                
                fig = go.Figure([go.Bar(
                    x=counts,
                    y=sources_display,
                    orientation='h',
                    marker_color='#00FF99'
                )])
                
                fig.update_layout(
                    title="N√∫mero de Citas por Fuente",
                    xaxis_title="N√∫mero de Citas",
                    yaxis_title="Fuente",
                    height=max(400, len(sources_list) * 30),
                    template="plotly_dark"
                )
                
                st.plotly_chart(fig, use_container_width=True)
        
        # Tab 4: Exportar
        with tab4:
            st.markdown("### üíæ Exportar a Word")
            
            st.markdown("""
            <div style="background: #34495e; padding: 1rem; border-radius: 8px; border-left: 4px solid #e67e22; color: #ecf0f1; margin: 1rem 0;">
                <strong>‚ÑπÔ∏è Exportaci√≥n a Word:</strong> Genera un documento de Word profesional con todos los conceptos extra√≠dos,
                incluyendo explicaciones, categor√≠as y citas para uso en tu investigaci√≥n.
            </div>
            """, unsafe_allow_html=True)
            
            # Opciones de exportaci√≥n
            col1, col2 = st.columns(2)
            
            with col1:
                include_explanations = st.checkbox(
                    "Incluir explicaciones de conceptos",
                    value=True,
                    help="Incluye las explicaciones generadas por la IA para cada concepto",
                    key="concepts_include_explanations"
                )
            
            with col2:
                include_citations = st.checkbox(
                    "Incluir citas y referencias",
                    value=True,
                    help="Incluye las citas espec√≠ficas donde aparece cada concepto",
                    key="concepts_include_citations"
                )
            
            # Informaci√≥n del documento
            st.markdown("#### üìÑ Informaci√≥n del Documento")
            
            col1, col2 = st.columns(2)
            with col1:
                document_title = st.text_input(
                    "T√≠tulo del documento",
                    value="An√°lisis de Conceptos Clave",
                    help="T√≠tulo que aparecer√° en el documento",
                    key="concepts_document_title"
                )
            
            with col2:
                author_name = st.text_input(
                    "Autor",
                    value="Investigador",
                    help="Nombre del autor del an√°lisis",
                    key="concepts_author_name"
                )
            
            # Generar documento Word
            if st.button("üìÑ Generar Documento Word", type="primary", use_container_width=True, key="concepts_generate_word"):
                try:
                    # Crear documento Word
                    doc_content = _generate_word_document(
                        concepts=concepts,
                        summary=summary,
                        title=document_title,
                        author=author_name,
                        include_explanations=include_explanations,
                        include_citations=include_citations
                    )
                    
                    st.download_button(
                        label="üíæ Descargar Documento Word",
                        data=doc_content,
                        file_name=f"{document_title.replace(' ', '_')}.docx",
                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                    )
                    
                    st.success("‚úÖ Documento Word generado correctamente")
                    
                except Exception as e:
                    st.error(f"‚ùå Error al generar documento Word: {str(e)}")
                    st.exception(e)


def _generate_word_document(
    concepts: List[ExtractedConcept],
    summary: Dict[str, Any],
    title: str,
    author: str,
    include_explanations: bool = True,
    include_citations: bool = True
) -> bytes:
    """
    Generar documento Word con los conceptos extra√≠dos
    
    Args:
        concepts: Lista de conceptos extra√≠dos
        summary: Resumen estad√≠stico
        title: T√≠tulo del documento
        author: Autor del documento
        include_explanations: Si incluir explicaciones
        include_citations: Si incluir citas
        
    Returns:
        Contenido del documento Word como bytes
    """
    try:
        from docx import Document
        from docx.shared import Inches, Pt
        from docx.enum.text import WD_ALIGN_PARAGRAPH
        from docx.enum.style import WD_STYLE_TYPE
        from docx.oxml.shared import OxmlElement, qn
        import io
    except ImportError:
        raise ImportError("python-docx es requerido para generar documentos Word. Instala con: pip install python-docx")
    
    # Crear documento
    doc = Document()
    
    # Configurar estilos
    title_style = doc.styles['Title']
    title_style.font.size = Pt(18)
    title_style.font.bold = True
    
    heading_style = doc.styles['Heading 1']
    heading_style.font.size = Pt(14)
    heading_style.font.bold = True
    
    # T√≠tulo del documento
    title_para = doc.add_heading(title, 0)
    title_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
    
    # Informaci√≥n del documento
    doc.add_paragraph(f"Autor: {author}")
    doc.add_paragraph(f"Fecha de generaci√≥n: {datetime.now().strftime('%d/%m/%Y %H:%M')}")
    doc.add_paragraph("")
    
    # Resumen ejecutivo
    doc.add_heading("Resumen Ejecutivo", level=1)
    
    summary_text = f"""
    Este documento presenta un an√°lisis cualitativo de conceptos clave extra√≠dos de documentos de investigaci√≥n.
    
    Estad√≠sticas del an√°lisis:
    ‚Ä¢ Total de conceptos identificados: {summary.get('total_concepts', 0)}
    ‚Ä¢ Fuentes analizadas: {summary.get('unique_sources', 0)}
    ‚Ä¢ Total de citas generadas: {summary.get('total_citations', 0)}
    ‚Ä¢ Relevancia promedio: {summary.get('avg_relevance', 0):.3f}
    """
    
    doc.add_paragraph(summary_text)
    doc.add_paragraph("")
    
    # Conceptos principales
    doc.add_heading("Conceptos Clave Identificados", level=1)
    
    for i, concept in enumerate(concepts, 1):
        # T√≠tulo del concepto
        concept_title = f"{i}. {concept.concept}"
        doc.add_heading(concept_title, level=2)
        
        # Informaci√≥n b√°sica
        info_text = f"""
        Frecuencia: {concept.frequency} apariciones
        Puntuaci√≥n de relevancia: {concept.relevance_score:.3f}
        Fuentes: {len(concept.sources)}
        """
        
        if hasattr(concept, 'category') and concept.category:
            info_text += f"Categor√≠a: {concept.category}\n"
        
        doc.add_paragraph(info_text)
        
        # Explicaci√≥n del concepto
        if include_explanations and concept.context_examples:
            explanation = None
            for example in concept.context_examples:
                if "Explicaci√≥n:" in example:
                    explanation = example.replace("Explicaci√≥n:", "").strip()
                    break
            
            if explanation:
                doc.add_heading("Explicaci√≥n", level=3)
                doc.add_paragraph(explanation)
        
        # Citas y referencias
        if include_citations and concept.citations:
            doc.add_heading("Referencias", level=3)
            
            for j, citation in enumerate(concept.citations[:3], 1):  # M√°ximo 3 citas
                citation_text = f"""
                Cita {j}:
                Fuente: {citation.source_file}
                Contexto: {citation.get_full_context(max_chars=200)}
                """
                doc.add_paragraph(citation_text)
        
        # Conceptos relacionados
        if concept.related_concepts:
            doc.add_heading("Conceptos Relacionados", level=3)
            related_text = ", ".join(concept.related_concepts)
            doc.add_paragraph(related_text)
        
        doc.add_paragraph("")  # Espacio entre conceptos
    
    # Bibliograf√≠a
    if include_citations:
        doc.add_heading("Bibliograf√≠a", level=1)
        
        # Obtener bibliograf√≠a del extractor
        from ...extractors.concept_extractor import ConceptExtractor
        extractor = ConceptExtractor()
        bibliography = extractor.citation_manager.generate_bibliography()
        
        for i, ref in enumerate(bibliography, 1):
            doc.add_paragraph(f"{i}. {ref}")
    
    # Guardar en bytes
    doc_bytes = io.BytesIO()
    doc.save(doc_bytes)
    doc_bytes.seek(0)
    
    return doc_bytes.getvalue()

