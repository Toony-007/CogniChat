# ğŸ”¬ MÃ³dulo de AnÃ¡lisis Cualitativo v2.0

## ğŸ“‹ DescripciÃ³n

Sistema modular de anÃ¡lisis cualitativo diseÃ±ado especÃ­ficamente para **asistir a investigadores** en el anÃ¡lisis profundo de contenido documental.

## ğŸ¯ Principios Fundamentales

### 1. ğŸ§­ Asistencia al Investigador
- Explicaciones claras sobre quÃ© hace cada anÃ¡lisis
- GuÃ­as de interpretaciÃ³n de resultados
- InformaciÃ³n metodolÃ³gica transparente

### 2. ğŸ§  Procesamiento Inteligente
- **NO copia y pega** informaciÃ³n
- Analiza, sintetiza y contextualiza
- Genera valor aÃ±adido mediante procesamiento

### 3. ğŸ“š FundamentaciÃ³n Completa
- Cada resultado respaldado por citas
- Sistema de trazabilidad completo
- VerificaciÃ³n de fuentes originales

### 4. ğŸ”¬ Transparencia MetodolÃ³gica
- Algoritmos documentados
- Limitaciones explÃ­citas
- ValidaciÃ³n humana recomendada

## ğŸ“ Estructura del MÃ³dulo

```
qualitative_analysis/
â”œâ”€â”€ __init__.py                      # API pÃºblica del mÃ³dulo
â”œâ”€â”€ README.md                        # Esta documentaciÃ³n
â”‚
â”œâ”€â”€ core/                            # Componentes fundamentales
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                    # ConfiguraciÃ³n centralizada
â”‚   â”œâ”€â”€ analyzer.py                  # Clase orquestadora principal
â”‚   â””â”€â”€ citation_manager.py          # Sistema de citaciÃ³n y referencias
â”‚
â”œâ”€â”€ extractors/                      # Extractores de informaciÃ³n
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ concept_extractor.py         # âœ… Extractor de conceptos clave (TF-IDF)
â”‚
â”œâ”€â”€ analyzers/                       # Analizadores avanzados (futuro)
â”‚   â””â”€â”€ theme_analyzer.py            # ğŸ”œ AnÃ¡lisis de temas (LDA)
â”‚
â”œâ”€â”€ visualizations/                  # Visualizaciones (futuro)
â”‚   â””â”€â”€ concept_map.py               # ğŸ”œ Mapas conceptuales
â”‚
â””â”€â”€ ui/                              # Interfaz de usuario
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ main_render.py               # FunciÃ³n render() principal
    â”œâ”€â”€ components/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ educational.py           # Componentes educativos
    â””â”€â”€ tabs/
        â”œâ”€â”€ __init__.py
        â””â”€â”€ concepts_tab.py          # âœ… Tab de conceptos clave
```

## ğŸš€ Uso RÃ¡pido

### Desde la AplicaciÃ³n (Streamlit)

```python
# En app.py (ya integrado)
from modules import qualitative_analysis

# Renderizar el mÃ³dulo completo
qualitative_analysis.render()
```

### Uso ProgramÃ¡tico

```python
from modules.qualitative_analysis import QualitativeAnalyzer, AnalysisConfig

# Crear configuraciÃ³n personalizada
config = AnalysisConfig(
    max_concepts=30,
    use_ngrams=True,
    enable_citations=True
)

# Inicializar analizador
analyzer = QualitativeAnalyzer(config)

# Preparar datos (chunks de documentos)
chunks = [
    {
        'content': 'Texto del documento...',
        'metadata': {
            'source_file': 'documento.pdf',
            'page_number': 1
        }
    },
    # mÃ¡s chunks...
]

# Extraer conceptos
concepts = analyzer.extract_concepts(chunks)

# Ver resultados
for concept in concepts[:10]:
    print(f"{concept.concept}: {concept.relevance_score:.3f}")
    print(f"  Fuentes: {', '.join(concept.sources)}")
    if concept.citations:
        citation = concept.citations[0]
        print(f"  Cita: {citation.format_citation()}")
```

## ğŸ“Š Sub-mÃ³dulos Implementados

### âœ… 1. ExtracciÃ³n de Conceptos Clave

**Estado:** Completamente implementado

**CaracterÃ­sticas:**
- ExtracciÃ³n inteligente usando TF-IDF
- DetecciÃ³n de n-gramas (frases completas)
- Sistema de citaciÃ³n integrado
- AnÃ¡lisis de co-ocurrencia
- ExportaciÃ³n en mÃºltiples formatos

**Algoritmo:** TF-IDF con detecciÃ³n de n-gramas (1-3 palabras)

**Ejemplo de uso:**
```python
from modules.qualitative_analysis.extractors import ConceptExtractor

extractor = ConceptExtractor(config)
concepts = extractor.extract_concepts(chunks)

# Ver concepto con citas
concept = concepts[0]
print(f"Concepto: {concept.concept}")
print(f"Relevancia: {concept.relevance_score:.3f}")
print(f"Frecuencia: {concept.frequency}")
print(f"Fuentes: {len(concept.sources)}")

# Ver primera cita
if concept.citations:
    citation = concept.get_first_citation()
    print(f"Cita: {citation.get_full_context()}")
```

## ğŸ”œ Sub-mÃ³dulos Planeados

### 2. AnÃ¡lisis de Temas (En desarrollo)
- LDA (Latent Dirichlet Allocation)
- Clustering semÃ¡ntico
- VisualizaciÃ³n de temas

### 3. AnÃ¡lisis de Sentimientos (En desarrollo)
- VADER + TextBlob
- AnÃ¡lisis contextual
- Tendencias emocionales

### 4. TriangulaciÃ³n (En desarrollo)
- ValidaciÃ³n cruzada entre fuentes
- AnÃ¡lisis de confiabilidad
- IdentificaciÃ³n de consensos

### 5. Mapas Conceptuales (En desarrollo)
- Visualizaciones interactivas
- AnÃ¡lisis de relaciones
- Redes semÃ¡nticas

## ğŸ“ GuÃ­a para Investigadores

### Â¿QuÃ© hace este mÃ³dulo?

Este sistema analiza tus documentos para identificar:
- **Conceptos clave**: TÃ©rminos y frases mÃ¡s importantes
- **Patrones**: Relaciones y conexiones entre conceptos
- **Fuentes**: De dÃ³nde proviene cada informaciÃ³n

### Â¿QuÃ© NO hace?

- âŒ NO copia y pega texto de documentos
- âŒ NO reemplaza el anÃ¡lisis humano
- âŒ NO interpreta significados automÃ¡ticamente

### Â¿CÃ³mo interpretar resultados?

1. **Score de relevancia (0.0 - 1.0)**:
   - 0.7-1.0: Concepto central
   - 0.4-0.7: Concepto importante
   - 0.0-0.4: Concepto secundario

2. **Frecuencia**: NÃºmero de apariciones en corpus

3. **Citas**: Referencias a fuentes originales para verificaciÃ³n

### Mejores PrÃ¡cticas

1. âœ… **Valida resultados**: Revisa que los conceptos extraÃ­dos tengan sentido
2. âœ… **Verifica citas**: Usa las citas para volver a las fuentes originales
3. âœ… **Contextualiza**: Interpreta segÃºn tu conocimiento del dominio
4. âœ… **Combina mÃ©todos**: Usa junto con anÃ¡lisis manual
5. âœ… **Documenta decisiones**: Registra cÃ³mo usas los resultados

## ğŸ”§ ConfiguraciÃ³n Avanzada

### AnalysisConfig

```python
config = AnalysisConfig(
    # ExtracciÃ³n de conceptos
    min_concept_frequency=2,      # Frecuencia mÃ­nima
    max_concepts=30,               # MÃ¡ximo a extraer
    use_ngrams=True,               # Detectar frases
    ngram_range=(1, 3),            # Rango de n-gramas
    
    # CitaciÃ³n
    enable_citations=True,         # Activar citas
    citation_context_chars=150,    # Contexto en citas
    
    # Interfaz
    show_explanations=True,        # Mostrar explicaciones
    show_methodology=True,         # Mostrar metodologÃ­a
    show_interpretation_guide=True,# GuÃ­as de interpretaciÃ³n
    
    # Rendimiento
    enable_cache=True,             # Activar cache
    parallel_processing=True,      # Procesamiento paralelo
    max_workers=4                  # Workers paralelos
)
```

## ğŸ“¤ Formatos de ExportaciÃ³n

### JSON Completo
```json
{
  "concept": "inteligencia artificial",
  "frequency": 15,
  "relevance_score": 0.856,
  "sources": ["doc1.pdf", "doc2.pdf"],
  "citations": [
    {
      "citation_id": "abc123",
      "source_file": "doc1.pdf",
      "content": "inteligencia artificial",
      "context_before": "...",
      "context_after": "..."
    }
  ]
}
```

### CSV
```csv
Concepto,Frecuencia,Relevancia,Num_Fuentes,Fuentes
inteligencia artificial,15,0.856,2,doc1.pdf; doc2.pdf
machine learning,12,0.742,2,doc1.pdf; doc2.pdf
```

## ğŸ› Troubleshooting

### Error: "scikit-learn es requerido"
```bash
pip install scikit-learn
```

### Error: "No hay documentos disponibles"
1. Ve a "ğŸ“„ GestiÃ³n de Documentos"
2. Sube tus archivos
3. Ve a "ğŸ§  Procesamiento RAG"
4. Procesa los documentos
5. Regresa a "ğŸ”¬ AnÃ¡lisis Cualitativo"

### Conceptos extraÃ­dos no tienen sentido
- Aumenta `min_concept_frequency`
- Verifica que los documentos estÃ©n en espaÃ±ol
- Revisa que los stopwords estÃ©n configurados correctamente

### Performance lento
- Reduce `max_concepts`
- Desactiva `use_ngrams` para bÃºsqueda mÃ¡s rÃ¡pida
- Activa `parallel_processing`

## ğŸ“š Referencias

### Algoritmos Utilizados

1. **TF-IDF** (Term Frequency-Inverse Document Frequency)
   - Referencia: Salton, G., & McGill, M. J. (1983). Introduction to modern information retrieval.

2. **N-gramas**
   - DetecciÃ³n de frases completas en lugar de palabras individuales

### Dependencias

- `scikit-learn`: Machine learning y TF-IDF
- `nltk`: Procesamiento de lenguaje natural
- `streamlit`: Interfaz de usuario
- `plotly`: Visualizaciones

## ğŸ¤ Contribuir

Este mÃ³dulo sigue una arquitectura modular que facilita agregar nuevos sub-mÃ³dulos:

1. Crea nuevo extractor en `extractors/`
2. Agrega interfaz en `ui/tabs/`
3. Actualiza `main_render.py` para incluir nueva tab
4. Documenta metodologÃ­a y limitaciones

## ğŸ“„ Licencia

Parte del proyecto CogniChat - Ver LICENSE en raÃ­z del proyecto.

---

**Desarrollado con enfoque en investigaciÃ³n cientÃ­fica** ğŸ”¬âœ¨

