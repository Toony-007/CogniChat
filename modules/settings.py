"""
Pesta√±a de configuraciones
"""

import streamlit as st
import json
import os
import sys
import time
from datetime import datetime
from pathlib import Path
from utils.error_handler import ErrorHandler
from utils.logger import setup_logger
from utils.ollama_client import OllamaClient
from config.settings import config

logger = setup_logger()
error_handler = ErrorHandler()

def render():
    """Renderizar la pesta√±a de configuraciones"""
    st.header("‚öôÔ∏è Configuraciones del Sistema")
    
    # Estado de conexi√≥n
    ollama_client = OllamaClient()
    ollama_available = ollama_client.is_available()
    
    if ollama_available:
        st.success("‚úÖ Ollama conectado - Configuraci√≥n disponible")
    else:
        st.error("‚ùå Ollama desconectado - Funcionalidad limitada")
    
    # Pesta√±as de configuraci√≥n con mejor organizaci√≥n
    tab1, tab2, tab3, tab4 = st.tabs([
        "ü§ñ Modelos IA", 
        "üîç RAG & Procesamiento", 
        "üîß Sistema", 
        "üíæ Backup & Restore"
    ])
    
    with tab1:
        render_models_config()
    
    with tab2:
        render_processing_config()
    
    with tab3:
        render_system_config()
    
    with tab4:
        render_export_import()

def render_models_config():
    """Configuraci√≥n de modelos de IA con dise√±o mejorado"""
    st.subheader("ü§ñ Configuraci√≥n de Modelos de IA")
    
    ollama_client = OllamaClient()
    
    if not ollama_client.is_available():
        st.error("‚ùå Ollama no est√° disponible. No se pueden configurar modelos.")
        st.markdown("""
        **Para resolver este problema:**
        1. Aseg√∫rate de que Ollama est√© instalado
        2. Ejecuta `ollama serve` en tu terminal
        3. Verifica que no haya problemas de firewall
        """)
        return
    
    # Obtener modelos disponibles con cach√©
    if 'available_models_settings' not in st.session_state or st.session_state.get('models_settings_last_refresh', 0) < time.time() - 300:
        # Actualizar cach√© cada 5 minutos
        available_models = ollama_client.get_available_models()
        st.session_state.available_models_settings = available_models
        st.session_state.models_settings_last_refresh = time.time()
    else:
        available_models = st.session_state.available_models_settings
    # Extraer nombres de modelos como cadenas
    model_names = []
    for model in available_models:
        if isinstance(model, dict):
            model_names.append(model.get('name', str(model)))
        else:
            model_names.append(str(model))
    
    # Secci√≥n de modelos principales
    st.markdown("### üéØ Modelos Principales")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 1rem; border-radius: 10px; color: white; margin-bottom: 1rem;">
            <h4 style="margin: 0; color: white;">üí¨ Modelo LLM Principal</h4>
            <p style="margin: 0.5rem 0 0 0; font-size: 0.9rem;">Modelo para generar respuestas</p>
        </div>
        """, unsafe_allow_html=True)
        
        if model_names:
            current_llm = st.session_state.get('selected_llm_model', config.DEFAULT_LLM_MODEL)
            
            selected_llm = st.selectbox(
                "Seleccionar modelo LLM",
                model_names,
                index=model_names.index(current_llm) if current_llm in model_names else 0,
                key="llm_model_selector",
                help="Modelo principal para generar respuestas del chatbot"
            )
            
            # Informaci√≥n del modelo
            if selected_llm:
                st.markdown(f"""
                <div style="background: #2c3e50; padding: 1rem; border-radius: 8px; border-left: 4px solid #667eea; color: #ecf0f1;">
                    <strong>üìä Informaci√≥n del Modelo</strong><br>
                    <small>‚Ä¢ Modelo: {selected_llm}</small><br>
                    <small>‚Ä¢ Tipo: Generaci√≥n de texto</small><br>
                    <small>‚Ä¢ Estado: ‚úÖ Disponible</small>
                </div>
                """, unsafe_allow_html=True)
            
            if st.button("üíæ Guardar Modelo LLM", type="primary", key="save_llm_model"):
                st.session_state.selected_llm_model = selected_llm
                st.success(f"‚úÖ Modelo LLM configurado: {selected_llm}")
                st.rerun()
        else:
            st.warning("‚ö†Ô∏è No hay modelos LLM disponibles")
            st.info("üí° Descarga un modelo usando: `ollama pull llama3.1:8b`")
    
    with col2:
        st.markdown("""
        <div style="background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); padding: 1rem; border-radius: 10px; color: white; margin-bottom: 1rem;">
            <h4 style="margin: 0; color: white;">üî§ Modelo de Embeddings</h4>
            <p style="margin: 0.5rem 0 0 0; font-size: 0.9rem;">Modelo para vectorizaci√≥n de texto</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Filtrar modelos de embeddings
        embedding_models = []
        for name in model_names:
            if isinstance(name, str) and ('embed' in name.lower() or 'minilm' in name.lower()):
                embedding_models.append(name)
        
        if embedding_models:
            current_embedding = st.session_state.get('selected_embedding_model', config.DEFAULT_EMBEDDING_MODEL)
            
            selected_embedding = st.selectbox(
                "Seleccionar modelo de embeddings",
                embedding_models,
                index=embedding_models.index(current_embedding) if current_embedding in embedding_models else 0,
                key="embedding_model_selector",
                help="Modelo para convertir texto en vectores para b√∫squeda sem√°ntica"
            )
            
            # Informaci√≥n del modelo
            if selected_embedding:
                st.markdown(f"""
                <div style="background: #2c3e50; padding: 1rem; border-radius: 8px; border-left: 4px solid #f093fb; color: #ecf0f1;">
                    <strong>üìä Informaci√≥n del Modelo</strong><br>
                    <small>‚Ä¢ Modelo: {selected_embedding}</small><br>
                    <small>‚Ä¢ Tipo: Embeddings</small><br>
                    <small>‚Ä¢ Estado: ‚úÖ Disponible</small>
                </div>
                """, unsafe_allow_html=True)
            
            if st.button("üíæ Guardar Modelo Embeddings", type="primary", key="save_embedding_model"):
                st.session_state.selected_embedding_model = selected_embedding
                st.success(f"‚úÖ Modelo de embeddings configurado: {selected_embedding}")
                st.rerun()
        else:
            st.warning("‚ö†Ô∏è No hay modelos de embeddings disponibles")
            st.info("üí° Descarga un modelo usando: `ollama pull nomic-embed-text`")
    
    st.divider()
    
    # Gesti√≥n de modelos
    st.markdown("### üì¶ Gesti√≥n de Modelos")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("**üìã Modelos Instalados:**")
        
        if available_models:
            for i, model in enumerate(available_models):
                # Extraer nombre del modelo correctamente
                if isinstance(model, dict):
                    model_name = model.get('name', str(model))
                else:
                    model_name = str(model)
                
                # Determinar tipo de modelo
                model_type = "üî§ Embeddings" if any(keyword in model_name.lower() for keyword in ['embed', 'minilm']) else "üí¨ LLM"
                
                st.markdown(f"""
                <div style="background: #34495e; padding: 0.8rem; border-radius: 8px; margin: 0.5rem 0; border-left: 4px solid #00FF99; color: #ecf0f1;">
                    <strong>{model_name}</strong> <span style="color: #bdc3c7;">({model_type})</span><br>
                    <small style="color: #95a5a6;">Estado: ‚úÖ Instalado y disponible</small>
                </div>
                """, unsafe_allow_html=True)
        else:
            st.info("üì¶ No hay modelos instalados")
    
    with col2:
        st.markdown("**üì• Descargar Modelo:**")
        
        # Modelos recomendados
        recommended_models = [
            "llama3.1:8b",
            "llama3.2:3b", 
            "nomic-embed-text",
            "all-minilm:latest"
        ]
        
        model_to_download = st.selectbox(
            "Modelo recomendado",
            ["Seleccionar..."] + recommended_models,
            help="Selecciona un modelo recomendado o escribe uno personalizado abajo"
        )
        
        custom_model = st.text_input(
            "O modelo personalizado",
            placeholder="Ej: deepseek-r1:7b",
            help="Nombre exacto del modelo de Ollama"
        )
        
        final_model = custom_model if custom_model else (model_to_download if model_to_download != "Seleccionar..." else "")
        
        if st.button("üì• Descargar Modelo", disabled=not final_model, key="download_model"):
            if final_model:
                with st.spinner(f"Descargando {final_model}..."):
                    success = ollama_client.pull_model(final_model)
                    if success:
                        st.success(f"‚úÖ Modelo {final_model} descargado correctamente")
                        st.rerun()
                    else:
                        st.error(f"‚ùå Error al descargar {final_model}")

def render_processing_config():
    """Configuraci√≥n de procesamiento RAG con dise√±o mejorado"""
    st.subheader("üîç Configuraci√≥n RAG y Procesamiento")
    
    # Configuraci√≥n RAG principal
    st.markdown("### üéØ Configuraci√≥n Principal RAG")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        <div style="background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%); padding: 1rem; border-radius: 10px; color: white; margin-bottom: 1rem;">
            <h4 style="margin: 0; color: white;">üìù Configuraci√≥n de Chunks</h4>
            <p style="margin: 0.5rem 0 0 0; font-size: 0.9rem;">Divisi√≥n de documentos en fragmentos</p>
        </div>
        """, unsafe_allow_html=True)
        
        chunk_size = st.slider(
            "Tama√±o de chunk (caracteres)",
            min_value=200,
            max_value=2000,
            value=st.session_state.get('chunk_size', config.CHUNK_SIZE),
            step=100,
            help="Tama√±o en caracteres de cada fragmento de texto"
        )
        
        chunk_overlap = st.slider(
            "Overlap entre chunks",
            min_value=0,
            max_value=500,
            value=st.session_state.get('chunk_overlap', config.CHUNK_OVERLAP),
            step=50,
            help="Solapamiento entre fragmentos consecutivos"
        )
        
        # Visualizaci√≥n del impacto
        estimated_chunks = 1000 // (chunk_size - chunk_overlap) if chunk_size > chunk_overlap else 1
        st.info(f"üìä Estimaci√≥n: ~{estimated_chunks} chunks por cada 1000 caracteres")
    
    with col2:
        st.markdown("""
        <div style="background: linear-gradient(135deg, #2c3e50 0%, #34495e 100%); padding: 1rem; border-radius: 10px; color: #ecf0f1; margin-bottom: 1rem;">
            <h4 style="margin: 0; color: #ecf0f1;">üéØ Configuraci√≥n de B√∫squeda</h4>
            <p style="margin: 0.5rem 0 0 0; font-size: 0.9rem;">Par√°metros de recuperaci√≥n de informaci√≥n</p>
        </div>
        """, unsafe_allow_html=True)
        
        max_retrieval_docs = st.slider(
            "M√°ximo documentos recuperados",
            min_value=1,
            max_value=20,
            value=st.session_state.get('max_retrieval_docs', config.MAX_RETRIEVAL_DOCS),
            help="N√∫mero m√°ximo de documentos a recuperar en RAG"
        )
        
        similarity_threshold = st.slider(
            "Umbral de similitud",
            min_value=0.0,
            max_value=1.0,
            value=st.session_state.get('similarity_threshold', config.SIMILARITY_THRESHOLD),
            step=0.1,
            help="Umbral m√≠nimo de similitud para considerar un documento relevante"
        )
        
        # Informaci√≥n sobre el umbral
        if similarity_threshold < 0.3:
            st.warning("‚ö†Ô∏è Umbral muy bajo - puede incluir contenido irrelevante")
        elif similarity_threshold > 0.8:
            st.warning("‚ö†Ô∏è Umbral muy alto - puede excluir contenido relevante")
        else:
            st.success("‚úÖ Umbral en rango √≥ptimo")
    
    # Configuraci√≥n de archivos
    st.markdown("### üìÅ Configuraci√≥n de Archivos")
    
    col1, col2 = st.columns(2)
    
    with col1:
        max_file_size = st.slider(
            "Tama√±o m√°ximo de archivo (MB)",
            min_value=1,
            max_value=500,
            value=st.session_state.get('max_file_size', config.MAX_FILE_SIZE_MB),
            help="Tama√±o m√°ximo permitido para archivos subidos"
        )
    
    with col2:
        st.markdown("**üìã Formatos Soportados:**")
        
        # Mostrar formatos en un dise√±o m√°s atractivo
        formats_html = ""
        for format_ext in config.SUPPORTED_FORMATS:
            formats_html += f'<span style="background: #34495e; color: #ecf0f1; padding: 0.2rem 0.5rem; border-radius: 4px; margin: 0.1rem; display: inline-block; font-size: 0.8rem;">{format_ext}</span> '
        
        st.markdown(f'<div style="line-height: 2;">{formats_html}</div>', unsafe_allow_html=True)
    
    # Bot√≥n para guardar configuraci√≥n
    if st.button("üíæ Guardar Configuraci√≥n RAG", type="primary", key="save_rag_config"):
        st.session_state.chunk_size = chunk_size
        st.session_state.chunk_overlap = chunk_overlap
        st.session_state.max_retrieval_docs = max_retrieval_docs
        st.session_state.similarity_threshold = similarity_threshold
        st.session_state.max_file_size = max_file_size
        
        st.success("‚úÖ Configuraci√≥n RAG guardada correctamente")
        st.rerun()
    
    st.divider()
    
    # Vista previa de configuraci√≥n actual
    st.markdown("### üëÄ Vista Previa de Configuraci√≥n Actual")
    
    current_config_display = {
        "Tama√±o de chunk": f"{chunk_size} caracteres",
        "Overlap": f"{chunk_overlap} caracteres",
        "Docs m√°ximos": f"{max_retrieval_docs} documentos",
        "Umbral similitud": f"{similarity_threshold:.1f}",
        "Tama√±o m√°ximo": f"{max_file_size} MB"
    }
    
    cols = st.columns(len(current_config_display))
    for i, (key, value) in enumerate(current_config_display.items()):
        with cols[i]:
            st.metric(key, value)

def render_system_config():
    """Configuraci√≥n del sistema con dise√±o mejorado"""
    st.subheader("üîß Configuraci√≥n del Sistema")
    
    # Configuraci√≥n de Ollama
    st.markdown("### ü§ñ Configuraci√≥n de Ollama")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 1rem; border-radius: 10px; color: white; margin-bottom: 1rem;">
            <h4 style="margin: 0; color: white;">üåê Conexi√≥n Ollama</h4>
            <p style="margin: 0.5rem 0 0 0; font-size: 0.9rem;">Configuraci√≥n de servidor Ollama</p>
        </div>
        """, unsafe_allow_html=True)
        
        ollama_url = st.text_input(
            "URL de Ollama",
            value=st.session_state.get('ollama_url', config.OLLAMA_BASE_URL),
            placeholder="http://localhost:11434",
            help="URL del servidor Ollama"
        )
        
        ollama_timeout = st.slider(
            "Timeout (segundos)",
            min_value=10,
            max_value=300,
            value=st.session_state.get('ollama_timeout', config.OLLAMA_TIMEOUT),
            help="Tiempo l√≠mite para conexiones con Ollama"
        )
        
        # Test de conexi√≥n
        if st.button("üîç Probar Conexi√≥n", key="test_connection"):
            try:
                test_client = OllamaClient()
                if test_client.is_available():
                    st.success("‚úÖ Conexi√≥n exitosa con Ollama")
                else:
                    st.error("‚ùå No se pudo conectar con Ollama")
            except Exception as e:
                st.error(f"‚ùå Error de conexi√≥n: {str(e)}")
    
    with col2:
        st.markdown("""
        <div style="background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%); padding: 1rem; border-radius: 10px; color: white; margin-bottom: 1rem;">
            <h4 style="margin: 0; color: white;">üìä Configuraci√≥n de Logs</h4>
            <p style="margin: 0.5rem 0 0 0; font-size: 0.9rem;">Nivel de registro del sistema</p>
        </div>
        """, unsafe_allow_html=True)
        
        log_level = st.selectbox(
            "Nivel de log",
            ["DEBUG", "INFO", "WARNING", "ERROR"],
            index=["DEBUG", "INFO", "WARNING", "ERROR"].index(
                st.session_state.get('log_level', config.LOG_LEVEL)
            ),
            help="Nivel de detalle en los logs del sistema"
        )
        
        # Informaci√≥n sobre niveles de log
        log_info = {
            "DEBUG": "üîç Informaci√≥n muy detallada para desarrollo",
            "INFO": "‚ÑπÔ∏è Informaci√≥n general del funcionamiento",
            "WARNING": "‚ö†Ô∏è Solo advertencias y errores",
            "ERROR": "‚ùå Solo errores cr√≠ticos"
        }
        
        st.info(log_info[log_level])
    
    # Bot√≥n para guardar configuraci√≥n del sistema
    if st.button("üíæ Guardar Configuraci√≥n del Sistema", type="primary", key="save_system_config_1"):
        st.session_state.ollama_url = ollama_url
        st.session_state.ollama_timeout = ollama_timeout
        st.session_state.log_level = log_level
        
        st.success("‚úÖ Configuraci√≥n del sistema guardada correctamente")
        st.rerun()
    
    st.divider()
    
    st.divider()
    
    # Configuraci√≥n de rutas del sistema
    st.markdown("### üìÅ Rutas del Sistema")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("**üìÇ Directorio de Datos**")
        data_dir = st.text_input(
            "Ruta de datos",
            value=st.session_state.get('data_dir', str(config.DATA_DIR)),
            help="Directorio principal para almacenar datos"
        )
        
        # Verificar si existe
        if os.path.exists(data_dir):
            st.success("‚úÖ Directorio existe")
        else:
            st.warning("‚ö†Ô∏è Directorio no existe")
            if st.button("üìÅ Crear Directorio", key="create_data_dir"):
                try:
                    os.makedirs(data_dir, exist_ok=True)
                    st.success("‚úÖ Directorio creado")
                    st.rerun()
                except Exception as e:
                    st.error(f"‚ùå Error: {str(e)}")
    
    with col2:
        st.markdown("**üì§ Directorio de Subidas**")
        uploads_dir = st.text_input(
            "Ruta de uploads",
            value=st.session_state.get('uploads_dir', str(config.UPLOADS_DIR)),
            help="Directorio para archivos subidos"
        )
        
        if os.path.exists(uploads_dir):
            file_count = len([f for f in os.listdir(uploads_dir) if os.path.isfile(os.path.join(uploads_dir, f))])
            st.success(f"‚úÖ {file_count} archivos")
        else:
            st.warning("‚ö†Ô∏è Directorio no existe")
    
    with col3:
        st.markdown("**üóÑÔ∏è Directorio de Cache**")
        cache_dir = st.text_input(
            "Ruta de cache",
            value=st.session_state.get('cache_dir', str(config.CACHE_DIR)),
            help="Directorio para archivos de cache"
        )
        
        if os.path.exists(cache_dir):
            st.success("‚úÖ Directorio existe")
            
            # Mostrar tama√±o del cache
            try:
                cache_size = sum(
                    os.path.getsize(os.path.join(cache_dir, f))
                    for f in os.listdir(cache_dir)
                    if os.path.isfile(os.path.join(cache_dir, f))
                )
                cache_size_mb = cache_size / (1024 * 1024)
                st.info(f"üìä Tama√±o: {cache_size_mb:.1f} MB")
                
                if st.button("üóëÔ∏è Limpiar Cache", key="clear_cache"):
                    try:
                        for f in os.listdir(cache_dir):
                            file_path = os.path.join(cache_dir, f)
                            if os.path.isfile(file_path):
                                os.remove(file_path)
                        st.success("‚úÖ Cache limpiado")
                        st.rerun()
                    except Exception as e:
                        st.error(f"‚ùå Error: {str(e)}")
            except Exception:
                st.warning("‚ö†Ô∏è No se pudo calcular el tama√±o")
        else:
            st.warning("‚ö†Ô∏è Directorio no existe")
    
    # Bot√≥n para guardar configuraci√≥n del sistema
    if st.button("üíæ Guardar Configuraci√≥n del Sistema", type="primary", key="save_system_config_2"):
        st.session_state.ollama_url = ollama_url
        st.session_state.ollama_timeout = ollama_timeout
        st.session_state.log_level = log_level
        st.session_state.data_dir = data_dir
        st.session_state.uploads_dir = uploads_dir
        st.session_state.cache_dir = cache_dir
        
        st.success("‚úÖ Configuraci√≥n del sistema guardada correctamente")
        st.rerun()
    
    st.divider()
    
    # Informaci√≥n del sistema
    st.markdown("### üíª Informaci√≥n del Sistema")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("üêç Python", f"{sys.version.split()[0]}")
        st.metric("üíæ Streamlit", st.__version__)
    
    with col2:
        # Informaci√≥n de memoria
        try:
            import psutil
            memory = psutil.virtual_memory()
            st.metric("üß† RAM Total", f"{memory.total / (1024**3):.1f} GB")
            st.metric("üìä RAM Usada", f"{memory.percent}%")
        except ImportError:
            st.metric("üß† RAM", "N/A")
            st.metric("üìä Uso", "N/A")
    
    with col3:
        # Informaci√≥n de disco
        try:
            import psutil
            disk = psutil.disk_usage('/')
            st.metric("üíΩ Disco Total", f"{disk.total / (1024**3):.1f} GB")
            st.metric("üìà Disco Usado", f"{(disk.used / disk.total) * 100:.1f}%")
        except:
            st.metric("üíΩ Disco", "N/A")
            st.metric("üìà Uso", "N/A")

def render_export_import():
    """Funcionalidad de backup y restore con dise√±o mejorado"""
    st.subheader("üíæ Backup & Restore")
    
    # Informaci√≥n general
    st.markdown("""
    <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 1.5rem; border-radius: 10px; color: white; margin-bottom: 2rem;">
        <h3 style="margin: 0; color: white;">üîÑ Gesti√≥n de Configuraciones</h3>
        <p style="margin: 0.5rem 0 0 0;">Exporta, importa y restaura las configuraciones del sistema</p>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### üì§ Exportar Configuraci√≥n")
        
        st.markdown("""
        <div style="background: #27ae60; color: #ecf0f1; padding: 1rem; border-radius: 8px; border-left: 4px solid #2ecc71; margin-bottom: 1rem;">
            <strong>üìã Incluye:</strong><br>
            <small>‚Ä¢ Modelos seleccionados</small><br>
            <small>‚Ä¢ Configuraci√≥n RAG</small><br>
            <small>‚Ä¢ Configuraci√≥n del sistema</small><br>
            <small>‚Ä¢ Par√°metros de procesamiento</small>
        </div>
        """, unsafe_allow_html=True)
        
        # Opciones de exportaci√≥n
        export_options = st.multiselect(
            "Seleccionar qu√© exportar",
            [
                "ü§ñ Configuraci√≥n de modelos",
                "üîç Configuraci√≥n RAG",
                "üîß Configuraci√≥n del sistema"
            ],
            default=[
                "ü§ñ Configuraci√≥n de modelos",
                "üîç Configuraci√≥n RAG",
                "üîß Configuraci√≥n del sistema"
            ]
        )
        
        if st.button("üì• Exportar Configuraci√≥n", type="primary", key="export_config"):
            try:
                # Crear configuraci√≥n para exportar
                export_config = {}
                
                if "ü§ñ Configuraci√≥n de modelos" in export_options:
                    export_config.update({
                        'selected_llm_model': st.session_state.get('selected_llm_model', config.DEFAULT_LLM_MODEL),
                        'selected_embedding_model': st.session_state.get('selected_embedding_model', config.DEFAULT_EMBEDDING_MODEL)
                    })
                
                if "üîç Configuraci√≥n RAG" in export_options:
                    export_config.update({
                        'chunk_size': st.session_state.get('chunk_size', config.CHUNK_SIZE),
                        'chunk_overlap': st.session_state.get('chunk_overlap', config.CHUNK_OVERLAP),
                        'max_retrieval_docs': st.session_state.get('max_retrieval_docs', config.MAX_RETRIEVAL_DOCS),
                        'similarity_threshold': st.session_state.get('similarity_threshold', config.SIMILARITY_THRESHOLD),
                        'max_file_size': st.session_state.get('max_file_size', config.MAX_FILE_SIZE_MB)
                    })
                
                if "üîß Configuraci√≥n del sistema" in export_options:
                    export_config.update({
                        'ollama_url': st.session_state.get('ollama_url', config.OLLAMA_BASE_URL),
                        'ollama_timeout': st.session_state.get('ollama_timeout', config.OLLAMA_TIMEOUT),
                        'log_level': st.session_state.get('log_level', config.LOG_LEVEL)
                    })
                
                # Agregar metadatos
                from datetime import datetime
                export_config['_metadata'] = {
                    'export_date': datetime.now().isoformat(),
                    'version': '1.0',
                    'app_name': 'CogniChat'
                }
                
                # Convertir a JSON
                config_json = json.dumps(export_config, indent=2, ensure_ascii=False)
                
                # Crear nombre de archivo
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"cognichat_config_{timestamp}.json"
                
                # Bot√≥n de descarga
                st.download_button(
                    label="üíæ Descargar Configuraci√≥n",
                    data=config_json,
                    file_name=filename,
                    mime="application/json"
                )
                
                st.success("‚úÖ Configuraci√≥n preparada para descarga")
                
            except Exception as e:
                st.error(f"‚ùå Error al exportar: {str(e)}")
    
    with col2:
        st.markdown("### üì• Importar Configuraci√≥n")
        
        st.markdown("""
        <div style="background: #3498db; color: #ecf0f1; padding: 1rem; border-radius: 8px; border-left: 4px solid #2980b9; margin-bottom: 1rem;">
            <strong>‚ö†Ô∏è Importante:</strong><br>
            <small>‚Ä¢ Esto sobrescribir√° la configuraci√≥n actual</small><br>
            <small>‚Ä¢ Se recomienda hacer backup antes</small><br>
            <small>‚Ä¢ Solo archivos JSON v√°lidos</small>
        </div>
        """, unsafe_allow_html=True)
        
        uploaded_config = st.file_uploader(
            "Seleccionar archivo de configuraci√≥n",
            type=['json'],
            help="Archivo JSON exportado previamente"
        )
        
        if uploaded_config is not None:
            try:
                # Leer y parsear el archivo
                config_data = json.load(uploaded_config)
                
                # Mostrar informaci√≥n del archivo
                if '_metadata' in config_data:
                    metadata = config_data['_metadata']
                    st.markdown(f"""
                    <div style="background: #34495e; color: #ecf0f1; padding: 1rem; border-radius: 8px; margin: 1rem 0;">
                        <strong>üìÑ Informaci√≥n del Archivo:</strong><br>
                        <small>‚Ä¢ Fecha: {metadata.get('export_date', 'N/A')}</small><br>
                        <small>‚Ä¢ Versi√≥n: {metadata.get('version', 'N/A')}</small><br>
                        <small>‚Ä¢ App: {metadata.get('app_name', 'N/A')}</small>
                    </div>
                    """, unsafe_allow_html=True)
                
                # Mostrar vista previa de configuraciones
                st.markdown("**üîç Vista Previa:**")
                
                preview_items = []
                if 'selected_llm_model' in config_data:
                    preview_items.append(f"‚Ä¢ LLM: {config_data['selected_llm_model']}")
                if 'selected_embedding_model' in config_data:
                    preview_items.append(f"‚Ä¢ Embeddings: {config_data['selected_embedding_model']}")
                if 'chunk_size' in config_data:
                    preview_items.append(f"‚Ä¢ Chunk size: {config_data['chunk_size']}")
                if 'ollama_url' in config_data:
                    preview_items.append(f"‚Ä¢ Ollama URL: {config_data['ollama_url']}")
                
                for item in preview_items[:5]:  # Mostrar solo los primeros 5
                    st.text(item)
                
                if len(preview_items) > 5:
                    st.text(f"... y {len(preview_items) - 5} m√°s")
                
                # Botones de acci√≥n
                col_import, col_cancel = st.columns(2)
                
                with col_import:
                    if st.button("‚úÖ Importar Configuraci√≥n", type="primary", key="import_config"):
                        try:
                            # Aplicar configuraci√≥n (excluyendo metadatos)
                            for key, value in config_data.items():
                                if not key.startswith('_'):
                                    if key == "llm_model":
                                        st.session_state.selected_llm_model = value
                                    elif key == "embedding_model":
                                        st.session_state.selected_embedding_model = value
                                    else:
                                        st.session_state[key] = value
                            
                            st.success("‚úÖ Configuraci√≥n importada correctamente")
                            st.rerun()
                            
                        except Exception as e:
                            st.error(f"‚ùå Error al importar: {str(e)}")
                
                with col_cancel:
                    if st.button("‚ùå Cancelar", key="cancel_import"):
                        st.rerun()
                        
            except json.JSONDecodeError:
                st.error("‚ùå Archivo JSON inv√°lido")
            except Exception as e:
                st.error(f"‚ùå Error al procesar archivo: {str(e)}")
    
    st.divider()
    
    # Secci√≥n de reset
    st.markdown("### üîÑ Restaurar Configuraci√≥n")
    
    st.markdown("""
    <div style="background: #d68910; color: #ecf0f1; padding: 1rem; border-radius: 8px; border-left: 4px solid #f39c12; margin-bottom: 1rem;">
        <strong>‚ö†Ô∏è Zona de Peligro</strong><br>
        <small>Estas acciones no se pueden deshacer</small>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("üîÑ Restaurar a Valores por Defecto", type="secondary", key="restore_defaults"):
            # Confirmar acci√≥n
            if 'confirm_reset' not in st.session_state:
                st.session_state.confirm_reset = True
                st.warning("‚ö†Ô∏è ¬øEst√°s seguro? Haz clic nuevamente para confirmar")
            else:
                # Limpiar configuraci√≥n
                config_keys = [
                    'selected_llm_model', 'selected_embedding_model',
                    'chunk_size', 'chunk_overlap', 'max_retrieval_docs',
                    'similarity_threshold', 'max_file_size',
                    'ollama_url', 'ollama_timeout', 'log_level'
                ]
                
                for key in config_keys:
                    if key in st.session_state:
                        del st.session_state[key]
                
                del st.session_state.confirm_reset
                st.success("‚úÖ Configuraci√≥n restaurada a valores por defecto")
                st.rerun()
    
    with col2:
        if st.button("üóëÔ∏è Limpiar Session State", type="secondary", key="clear_session_state"):
            if 'confirm_clear' not in st.session_state:
                st.session_state.confirm_clear = True
                st.error("üö® ¬øEst√°s seguro? Esto limpiar√° toda la sesi√≥n. Haz clic nuevamente para confirmar")
            else:
                try:
                    # Limpiar session state
                    for key in list(st.session_state.keys()):
                        if not key.startswith('_'):
                            del st.session_state[key]
                    
                    del st.session_state.confirm_clear
                    st.success("‚úÖ Session state limpiado")
                    st.rerun()
                    
                except Exception as e:
                    st.error(f"‚ùå Error al limpiar: {str(e)}")
                    if 'confirm_clear' in st.session_state:
                        del st.session_state.confirm_clear