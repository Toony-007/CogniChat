#!/usr/bin/env python3
"""
Script de prueba para el enfoque h√≠brido TF-IDF + DeepSeek R1
Demuestra la mejora en la extracci√≥n de conceptos
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from modules.qualitative_analysis.extractors.concept_extractor import ConceptExtractor
from modules.qualitative_analysis.core.config import AnalysisConfig

def create_test_document():
    """Crear un documento de prueba con contenido acad√©mico complejo"""
    return [
        {
            'content': """
            El modelo VARK (Visual, Aural, Read/Write, Kinesthetic) representa una metodolog√≠a 
            educativa innovadora que identifica cuatro estilos de aprendizaje principales en 
            estudiantes de diferentes contextos socioecon√≥micos. Los estudiantes visuales 
            demuestran preferencias marcadas por diagramas, mapas conceptuales y 
            representaciones gr√°ficas, mientras que los estudiantes auditivos desarrollan 
            mejor sus competencias a trav√©s de discusiones grupales, conferencias magistrales 
            y explicaciones orales interactivas.
            
            La investigaci√≥n cualitativa en educaci√≥n utiliza m√©todos etnogr√°ficos como 
            entrevistas en profundidad, grupos focales participativos y observaci√≥n 
            participante para recopilar datos emp√≠ricos sobre experiencias de aprendizaje. 
            El an√°lisis tem√°tico emergente es una t√©cnica de an√°lisis cualitativo que permite
            identificar patrones recurrentes y temas emergentes en los datos, facilitando
            la construcci√≥n de teor√≠as fundamentadas en la realidad educativa.
            
            La validez interna en investigaci√≥n cualitativa se refiere a la credibilidad 
            y autenticidad de los hallazgos, mientras que la validez externa se relaciona 
            con la transferibilidad y aplicabilidad de los resultados a otros contextos 
            educativos similares. La triangulaci√≥n metodol√≥gica fortalece la confiabilidad
            de los datos mediante la convergencia de m√∫ltiples fuentes de informaci√≥n.
            
            Los procesos de resiliencia acad√©mica emergen cuando los estudiantes enfrentan
            adversidades socioecon√≥micas pero mantienen su motivaci√≥n intr√≠nseca hacia
            el aprendizaje. Las redes de apoyo educativo incluyen no solo a los docentes
            sino tambi√©n a pares, familiares y mentores comunitarios que facilitan
            la persistencia estudiantil en contextos desfavorecidos.
            """,
            'metadata': {
                'source_file': 'documento_prueba.pdf',
                'page_number': 1
            }
        }
    ]

def test_traditional_extraction():
    """Probar extracci√≥n tradicional (solo TF-IDF)"""
    print("=" * 60)
    print("üîç PRUEBA: Extracci√≥n tradicional (solo TF-IDF)")
    print("=" * 60)
    
    # Configuraci√≥n sin LLM
    config = AnalysisConfig(
        enable_llm_refinement=False,
        max_concepts=10,
        min_concept_frequency=1
    )
    
    extractor = ConceptExtractor(config)
    chunks = create_test_document()
    
    concepts = extractor.extract_concepts(chunks)
    
    print(f"\nüìä Conceptos extra√≠dos (TF-IDF puro): {len(concepts)}")
    for i, concept in enumerate(concepts[:5], 1):
        print(f"{i}. {concept.concept} (freq: {concept.frequency}, score: {concept.relevance_score:.3f})")
    
    return concepts

def test_hybrid_extraction():
    """Probar extracci√≥n h√≠brida (TF-IDF + DeepSeek R1)"""
    print("\n" + "=" * 60)
    print("ü§ñ PRUEBA: Extracci√≥n h√≠brida (TF-IDF + DeepSeek R1)")
    print("=" * 60)
    
    # Configuraci√≥n con LLM
    config = AnalysisConfig(
        enable_llm_refinement=True,
        llm_model="deepseek-r1:7b",
        llm_temperature=0.3,
        max_final_concepts=8,
        include_concept_explanations=True,
        max_concepts=15,  # Candidatos iniciales
        min_concept_frequency=1
    )
    
    extractor = ConceptExtractor(config)
    chunks = create_test_document()
    
    concepts = extractor.extract_concepts(chunks)
    
    print(f"\nüìä Conceptos refinados (H√≠brido): {len(concepts)}")
    for i, concept in enumerate(concepts, 1):
        print(f"{i}. {concept.concept} (freq: {concept.frequency}, score: {concept.relevance_score:.3f})")
        if concept.category:
            print(f"   üìÇ Categor√≠a: {concept.category}")
        if concept.context_examples and any("Explicaci√≥n:" in ex for ex in concept.context_examples):
            explanation = next((ex for ex in concept.context_examples if "Explicaci√≥n:" in ex), "")
            print(f"   üí° {explanation}")
        if concept.related_concepts:
            print(f"   üîó Relacionado con: {', '.join(concept.related_concepts[:3])}")
        print()
    
    return concepts

def compare_results(traditional_concepts, hybrid_concepts):
    """Comparar resultados entre ambos enfoques"""
    print("=" * 60)
    print("üìà COMPARACI√ìN DE RESULTADOS")
    print("=" * 60)
    
    print(f"\nüîç TF-IDF puro: {len(traditional_concepts)} conceptos")
    print("Conceptos extra√≠dos (tradicionales):")
    for concept in traditional_concepts[:5]:
        print(f"  ‚Ä¢ {concept.concept} (freq: {concept.frequency}, score: {concept.relevance_score:.3f})")
    
    print(f"\nü§ñ H√≠brido (TF-IDF + LLM): {len(hybrid_concepts)} conceptos")
    print("Conceptos refinados (acad√©micos profundos):")
    for concept in hybrid_concepts:
        print(f"  ‚Ä¢ {concept.concept}")
        if concept.category:
            print(f"    üìÇ Categor√≠a: {concept.category}")
        if concept.context_examples and any("Explicaci√≥n:" in ex for ex in concept.context_examples):
            explanation = next((ex for ex in concept.context_examples if "Explicaci√≥n:" in ex), "")
            print(f"    üí° {explanation}")
        if concept.related_concepts:
            print(f"    üîó Relacionado: {', '.join(concept.related_concepts[:2])}")
        print()
    
    print(f"\n‚ú® MEJORAS OBSERVADAS:")
    print("‚Ä¢ Conceptos profundos y acad√©micos (no palabras simples)")
    print("‚Ä¢ Captura de procesos, relaciones y fen√≥menos complejos")
    print("‚Ä¢ Eliminaci√≥n de t√©rminos gen√©ricos y letras sueltas")
    print("‚Ä¢ Consolidaci√≥n inteligente de conceptos relacionados")
    print("‚Ä¢ Categorizaci√≥n autom√°tica por tipo de fen√≥meno")
    print("‚Ä¢ Explicaciones contextuales que revelan significado")
    print("‚Ä¢ Conceptos que explican 'c√≥mo' y 'por qu√©', no solo 'qu√©'")
    
    print(f"\nüéØ EJEMPLOS DE TRANSFORMACI√ìN:")
    print("‚ùå Antes: 'documento', 'centro educativo', 'texto'")
    print("‚úÖ Despu√©s: 'Resiliencia acad√©mica en contextos desfavorecidos'")
    print("‚úÖ Despu√©s: 'Redes de apoyo educativo comunitario'")
    print("‚úÖ Despu√©s: 'Procesos de motivaci√≥n intr√≠nseca estudiantil'")

def main():
    """Funci√≥n principal de prueba"""
    print("üöÄ INICIANDO PRUEBA DEL ENFOQUE H√çBRIDO")
    print("TF-IDF + DeepSeek R1 para extracci√≥n de conceptos")
    print("=" * 60)
    
    try:
        # Verificar disponibilidad de Ollama
        from utils.ollama_client import ollama_client
        if not ollama_client.is_available():
            print("‚ö†Ô∏è  ADVERTENCIA: Ollama no est√° disponible")
            print("   El refinamiento con LLM no funcionar√°")
            print("   Solo se ejecutar√° la extracci√≥n TF-IDF")
        
        # Ejecutar pruebas
        traditional_concepts = test_traditional_extraction()
        hybrid_concepts = test_hybrid_extraction()
        
        # Comparar resultados
        compare_results(traditional_concepts, hybrid_concepts)
        
        print("\n‚úÖ PRUEBA COMPLETADA")
        print("El enfoque h√≠brido est√° funcionando correctamente")
        
    except Exception as e:
        print(f"\n‚ùå ERROR durante la prueba: {e}")
        print("Verifica que todas las dependencias est√©n instaladas")

if __name__ == "__main__":
    main()
